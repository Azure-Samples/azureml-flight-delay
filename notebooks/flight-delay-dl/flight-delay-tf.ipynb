{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Flight Delay Demo - Deep Learning & Labeling\n",
        "\n",
        "## Install prerequisites\n",
        "\n",
        "Before running the notebook, make sure the correct versions of these libraries are installed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install --upgrade tensorflow-gpu==1.13.2 tensorflow==1.13.2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "import logging\r\n",
        "logging.basicConfig(level = logging.ERROR)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import open source Python libraries\n",
        "\n",
        "Import open source dependencies and modules that will be used through out this notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import requests\r\n",
        "import utils\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import environment_definition\r\n",
        "import string_int_label_map_pb2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Azure Machine Learning Python SDK\n",
        "\n",
        "Import Azure Machine Learning SDK modules."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Workspace, Experiment\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "from azureml.core.image import ContainerImage\r\n",
        "from azureml.train.dnn import TensorFlow\r\n",
        "from azureml.core.runconfig import AzureContainerRegistry, DockerEnvironment, EnvironmentDefinition, PythonEnvironment\r\n",
        "\r\n",
        "from azureml.core.compute import AksCompute, ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core.webservice import Webservice, AksWebservice\r\n",
        "\r\n",
        "from azureml.core.image import Image"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Azure Machine Learning workspace\n",
        "\n",
        "In the next cell, we will create a new Workspace config object using the `<subscription_id>`, `<resource_group_name>`, and `<workspace_name>`. This will fetch the matching Workspace and prompt you for authentication. Please click on the link and input the provided details.\n",
        "\n",
        "For more information on **Workspace**, please visit: [Microsoft Workspace Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py)\n",
        "\n",
        "`<subscription_id>` = You can get this ID from the landing page of your Resource Group.\n",
        "\n",
        "`<resource_group_name>` = This is the name of your Resource Group.\n",
        "\n",
        "`<workspace_name>` = This is the name of your Workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.workspace import Workspace\r\n",
        "\r\n",
        "try:    \r\n",
        "    # Get instance of the Workspace and write it to config file\r\n",
        "    ws = Workspace(\r\n",
        "        subscription_id = '<subscription_id>', \r\n",
        "        resource_group = '<resource_group>', \r\n",
        "        workspace_name = '<workspace_name>')\r\n",
        "\r\n",
        "    # Writes workspace config file\r\n",
        "    ws.write_config()\r\n",
        "    \r\n",
        "    print('Library configuration succeeded')\r\n",
        "except Exception as e:\r\n",
        "    print(e)\r\n",
        "    print('Workspace not found')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect and prepare training data\n",
        "\n",
        "Let's take a look at a subset of images used for training our model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<HTML>\n",
        "    <TR>\n",
        "        <TD><img src=\"./images/train/default/000.jpg\" /></TD>\n",
        "        <TD><img src=\"./images/train/default/001.jpg\" /></TD>\n",
        "        <TD><img src=\"./images/train/default/002.jpg\" /></TD>\n",
        "        <TD><img src=\"./images/train/default/003.jpg\" /></TD>\n",
        "    </TR>\n",
        "    <TR>\n",
        "        <TD><img src=\"./images/train/default/004.jpg\" /></TD>\n",
        "        <TD><img src=\"./images/train/default/005.jpg\" /></TD>\n",
        "        <TD><img src=\"./images/train/default/006.jpg\" /></TD>\n",
        "        <TD><img src=\"./images/train/default/007.jpg\" /></TD>\n",
        "    </TR>\n",
        "</HTML>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras: Data augmentation\n",
        "\n",
        "The `tf.keras.preprocessing.image.ImageDataGenerator` function generates batches of tensor image data with real-time data augmentation."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "\r\n",
        "augmented_folder = './images/augmented'\r\n",
        "\r\n",
        "# Working directory\r\n",
        "if not os.path.exists(augmented_folder):\r\n",
        "    os.makedirs(augmented_folder)\r\n",
        "    \r\n",
        "gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=17, width_shift_range=0.12,\r\n",
        "                     height_shift_range=0.12, zoom_range=0.12, horizontal_flip=True)\r\n",
        "\r\n",
        "path = 'images/'\r\n",
        "i = 0\r\n",
        "for batch in gen.flow_from_directory('images/train', target_size=(224,224),\r\n",
        "    class_mode=None, shuffle=False, batch_size=32,\r\n",
        "    save_to_dir=augmented_folder, save_prefix='hi'):\r\n",
        "\r\n",
        "    i += 1\r\n",
        "    if i > 10:\r\n",
        "        break  "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras: Augmented dataset sample\n",
        "\n",
        "Review images generated by Keras."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from IPython.display import Image, display\r\n",
        "from glob import glob\r\n",
        "\r\n",
        "listofImageNames = glob(path+'augmented/*.png', recursive=True)\r\n",
        "for imageName in listofImageNames[:1]:\r\n",
        "    display(Image(filename=imageName))\r\n",
        "    print(imageName)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import shutil\r\n",
        "\r\n",
        "shutil.rmtree(augmented_folder)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Azure Machine Learning experiment\n",
        "\n",
        "The Experiment constructor allows to create an experiment instance. The constructor takes in the current workspace, which is fetched by calling `Workspace.from_config()` and an experiment name. \n",
        "\n",
        "For more information on **Experiment**, please visit: [Microsoft Experiment Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "experiment_name = 'flight-delay-tf'\r\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create auto-scaling AML Compute GPU cluster\n",
        "\n",
        "Firstly, check for the existence of the cluster. If it already exists, we are able to reuse it. Checking for the existence of the cluster can be performed by calling the constructor `ComputeTarget()` with the current workspace and name of the cluster.\n",
        "\n",
        "In case the cluster does not exist, the next step will be to provide a configuration for the new AML cluster by calling the function `AmlCompute.provisioning_configuration()`. It takes as parameters the VM size and the max number of nodes that the cluster can scale up to. After the configuration has executed, `ComputeTarget.create()` should be called with the previously configuration object and the workspace object.\n",
        "\n",
        "For more information on **ComputeTarget**, please visit: [Microsoft ComputeTarget Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computetarget?view=azure-ml-py)\n",
        "\n",
        "For more information on **AmlCompute**, please visit: [Microsoft AmlCompute Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.akscompute?view=azure-ml-py)\n",
        "\n",
        "\n",
        "**Note:** Please wait for the execution of the cell to finish before moving forward."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Choose a name for your GPU cluster\r\n",
        "cluster_name = \"gpucluster\"\r\n",
        "\r\n",
        "# Verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    gpu_cluster = ComputeTarget(workspace = ws, name = cluster_name)\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\r\n",
        "                                                           min_nodes=0,\r\n",
        "                                                           max_nodes=4,\r\n",
        "                                                           admin_username=\"theadmin\",\r\n",
        "                                                           admin_user_password=\"Password123\")\r\n",
        "                                                           \r\n",
        "    gpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "\r\n",
        "gpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload training data to Azure Machine Learning Data Store\n",
        "\n",
        "To register our training data with our Workspace we need to get the data into the data store. The Workspace will already have a default data store. The function `ws.get_default_datastore()` returns an instance of the data store associated with the Workspace, to which files will be uploaded by calling `ds.upload()`.\n",
        "\n",
        "For more information on **Datastore**, please visit: [Microsoft Datastore Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore?view=azure-ml-py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Prepare data\r\n",
        "ds = ws.get_default_datastore()\r\n",
        "ds.upload('./data')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "env_def = EnvironmentDefinition()\r\n",
        "env_def.docker = environment_definition.docker_config\r\n",
        "env_def.python = environment_definition.python_config\r\n",
        "\r\n",
        "print('Base docker image: ' + env_def.docker.base_image)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model using TensorFlow estimator on the GPU cluster\n",
        "\n",
        "Create the TensorFlow estimator and submit the experiment. The TensorFlow instance takes in as parameters the `compute_target` that will be our GPU Cluster created previously, `entry_script` that points to our main training script: `train.py`. On the other hand `inputs` and `environment_definitions` take care of mounting the data store to our remote training cluster and of the dependencies requiered on this cluster for the training to start."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "script_params = {\r\n",
        "    '--model_dir': './outputs',\r\n",
        "    '--pipeline_config_path': './faster_rcnn_resnet101_bird.config'\r\n",
        "}\r\n",
        "\r\n",
        "tf_est = TensorFlow(source_directory = './train/src',\r\n",
        "                    script_params=script_params,\r\n",
        "                    compute_target=gpu_cluster,\r\n",
        "                    entry_script='train.py',\r\n",
        "                    inputs=[ds.as_download(path_on_compute='/data')],\r\n",
        "                    environment_definition=env_def\r\n",
        "                   )\r\n",
        "run = experiment.submit(tf_est)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display train.py\n",
        "\n",
        "Let's take a look at our training script. As you can see, it's a standard TensorFlow training script."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "f = open(\"./train/src/train.py\", \"r\") \r\n",
        "print(f.read())"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment run details\n",
        "\n",
        "While the experiment is running, we can monitor it through the AML widget."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "run = Run(experiment=experiment, run_id=run.id)\r\n",
        "RunDetails(run).show() "
      ],
      "outputs": [],
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start TensorBoard\n",
        "\n",
        "The `export_to_tensorboard` function exports experiment run history to Tensorboard logs ready for Tensorboard visualization.\n",
        "\n",
        "For more information on ***tensorboard Package***, please visit: [Microsoft tensorboard Package Documentation](https://docs.microsoft.com/en-us/python/api/azureml-tensorboard/azureml.tensorboard?view=azure-ml-py)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Export Run History to Tensorboard logs\r\n",
        "from azureml.tensorboard.export import export_to_tensorboard\r\n",
        "from azureml.tensorboard import Tensorboard\r\n",
        "import os\r\n",
        "\r\n",
        "logdir = 'exportedTBlogs'\r\n",
        "log_path = os.path.join(os.getcwd(), logdir)\r\n",
        "try:\r\n",
        "    os.stat(log_path)\r\n",
        "except os.error:\r\n",
        "    os.mkdir(log_path)\r\n",
        "\r\n",
        "export_to_tensorboard(run, logdir)\r\n",
        "\r\n",
        "# The Tensorboard constructor takes an array of runs, so be sure and pass it in as a single-element array here\r\n",
        "tb = Tensorboard([], local_root=logdir, port=6006)\r\n",
        "\r\n",
        "# If successful, start() returns a string with the URI of the instance.\r\n",
        "tb.start()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop TensorBoard\n",
        "\n",
        "The `Tensorboard.stop()` function stops the Tensorboard instance."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tb.stop()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter training\n",
        "\n",
        "Hyperparameters are adjustable parameters for model training that guide the training process. The HyperDrive package helps automate choosing these parameters.\n",
        "\n",
        "The `choice` function specifies a discrete set of options to sample from.\n",
        "\n",
        "The `HyperDriveConfig Class` is a configuration that defines a HyperDrive run. HyperDrive configuration includes information about hyperparameter space sampling, termination policy, primary metric, resume from configuration, estimator, and the compute target to execute the experiment runs on.\n",
        "\n",
        "The `normal` function specifies a real value that is normally-distributed with mean mu and standard deviation sigma.\n",
        "\n",
        "The `PrimaryMetricGoal Enum` defines supported metric goals for hyperparameter tuning. A metric goal is used to determine whether a higher value for a metric is better or worse. Metric goals are used when comparing runs based on the primary metric. For example, you may want to maximize accuracy or minimize error.\n",
        "\n",
        "The `RandomParameterSampling Class` defines random sampling over a hyperparameter search space.\n",
        "\n",
        "For more information on ***HyperDrive Package***, please visit: [Microsoft hyperDriver Package Documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive?view=azure-ml-py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.train.hyperdrive import BanditPolicy, choice, HyperDriveConfig, normal, PrimaryMetricGoal, RandomParameterSampling\r\n",
        "\r\n",
        "param_sampling = RandomParameterSampling({\r\n",
        "    \"--batch_size\": choice(1, 4, 8, 16),\r\n",
        "    \"--learning_rate\": normal(0.0002, 0.0006)\r\n",
        "})\r\n",
        "\r\n",
        "hyperdrive_run_config = HyperDriveConfig(estimator=tf_est,\r\n",
        "                          hyperparameter_sampling=param_sampling,\r\n",
        "                          primary_metric_name=\"loss\", \r\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\r\n",
        "                          max_total_runs=10,\r\n",
        "                          max_concurrent_runs=4)\r\n",
        "\r\n",
        "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "hyperdrive_run = Run(experiment, run_id=hyperdrive_run.id)\r\n",
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register model\n",
        "\n",
        "After the experiment has ended successfully we will need to download the outputs of it in order for us to register the model against our Azure Machine Learning workspace.\n",
        "\n",
        "The `get_file_names()` function lists the files that are stored in association with the run.\n",
        "\n",
        "The `download_file()` function downloads an associated file from storage. As parameters it receives the `name` of the artifact to be downloaded, and the `output_file_path` which is the local path where to store the artifact.\n",
        "\n",
        "For more information on ***Run Class***, please visit: [Microsoft Run Class Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.run?view=azure-ml-py#download-file-name--output-file-path-none---validate-checksum-false-)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "files = run.get_file_names()\r\n",
        "results = [file for file in files if ('outputs/model' in file or 'outputs/checkpoint' in file or 'outputs/events' in file or 'outputs/graph' in file or 'outputs/frozen_inference_graph' in file)]\r\n",
        "run.download_file('outputs/frozen_inference_graph.pb', './outputs/frozen_inference_graph.pb')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, register the model obtained from the best run. In order to register the model, the function `register_model()` should be called. This will take care of registering the model obtained from the best run.\n",
        "\n",
        "The `Model.register()` function registers a model with the provided workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# register the model for deployment\r\n",
        "model = Model.register(model_path = \"./outputs/frozen_inference_graph.pb\",\r\n",
        "                       model_name = \"frozen_inference_graph.pb\",\r\n",
        "                       description = \"Flight Delay Image\",\r\n",
        "                       workspace = ws)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment\n",
        "## Fetch Azure Kubernetes Cluster\n",
        "\n",
        "Let's get a reference to our already existing AKS Cluster `flight-delay-aks`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.compute import AksCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "from azureml.exceptions import ComputeTargetException\r\n",
        "\r\n",
        "prov_config = AksCompute.provisioning_configuration(location='westus2')\r\n",
        "\r\n",
        "try:\r\n",
        "    aks_target = AksCompute(ws, 'flight-delay-aks')\r\n",
        "except ComputeTargetException:\r\n",
        "    # Create the cluster\r\n",
        "    aks_target = ComputeTarget.create(workspace = ws, \r\n",
        "                            name = 'flight-delay-aks', \r\n",
        "                            provisioning_configuration = prov_config)\r\n",
        "    aks_target.wait_for_completion(True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the AKS cluster has been deployed, it’s time to create an `InferenceConfig` object by calling its constructor and passing the runtime type, the path to the `entry_script` (score.py), and the `conda_file` (the previously created file that holds the environment dependencies).\n",
        "\n",
        "Next, define the configuration of the web service to deploy. This is done by calling `AksWebservice.deploy_configuration()` and passing along the number of `cpu_cores` and `memory_gb` that the service needs.\n",
        "\n",
        "Finally, in order to deploy the model and service to the created AKS cluster, the function `Model.deploy()` should be called, passing along the workspace object, a list of models to deploy, the defined inference configuration, deployment configuration, and the AKS object created in the step above.\n",
        "\n",
        "For more information on **InferenceConfig**, please visit: [Microsoft InferenceConfig Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py)\n",
        "\n",
        "For more information on **AksWebService**, please visit: [Microsoft AksWebService Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.akswebservice?view=azure-ml-py)\n",
        "\n",
        "For more information on **Model**, please visit: [Microsoft Model Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py)\n",
        "\n",
        "\n",
        "**Note:** Please wait for the execution of the cell to finish before moving forward."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AksWebservice\r\n",
        "from azureml.core.model import Model\r\n",
        "from azureml.exceptions import WebserviceException\r\n",
        "\r\n",
        "# Create an inference config object based on the score.py and myenv.yml from previous steps\r\n",
        "inference_config = InferenceConfig(runtime= \"python\",\r\n",
        "                                    entry_script=\"score.py\",\r\n",
        "                                    conda_file=\"score.yml\")\r\n",
        "\r\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, \r\n",
        "                                                        memory_gb = 1)\r\n",
        "\r\n",
        "try:\r\n",
        "    service = AksWebservice(ws, 'fd-image-service')\r\n",
        "    print(service.state)\r\n",
        "except WebserviceException:\r\n",
        "    service = Model.deploy(ws, \r\n",
        "                        'fd-image-service', \r\n",
        "                        [model], \r\n",
        "                        inference_config, \r\n",
        "                        deployment_config, \r\n",
        "                        aks_target)\r\n",
        "    service.wait_for_deployment(show_output = True)\r\n",
        "    print(service.state)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the service\n",
        "\n",
        "Now with test data, we can get it into a suitable format to consume the web service. First an instance of the web service should be obtained by calling the constructor `Webservice()` with the Workspace object and the service name as parameters. Finally, call the service via POST using the `requests` module. `requests.post()` will call the deployed web service. It takes for parameters the service URL, the test data, and a headers dictionary that contains the authentication token.\n",
        "\n",
        "For more information on **Webservice**, please visit: [Microsoft Webservice Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice?view=azure-ml-py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Test the service\r\n",
        "test_image = './images/train/default/000.JPG'\r\n",
        "image = open(test_image, 'rb')\r\n",
        "input_data = image.read()\r\n",
        "image.close()\r\n",
        "\r\n",
        "aks_service_name = 'fd-image-service'\r\n",
        "aks_service = AksWebservice(workspace=ws, name=aks_service_name)\r\n",
        "\r\n",
        "auth = 'Bearer ' + aks_service.get_keys()[0]\r\n",
        "uri = aks_service.scoring_uri\r\n",
        "\r\n",
        "res = requests.post(url=uri,\r\n",
        "                    data=input_data,\r\n",
        "                    headers={'Authorization': auth, 'Content-Type': 'application/octet-stream'})\r\n",
        "\r\n",
        "results = res.json()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's parse the response received from the Webservice."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#import utils\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "# Show the results\r\n",
        "image = Image.open(test_image)\r\n",
        "image_np = utils.load_image_into_numpy_array(image)\r\n",
        "category_index = utils.create_category_index_from_labelmap('./score/samples/label_map.pbtxt', use_display_name=True)\r\n",
        "\r\n",
        "utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "    image_np,\r\n",
        "    np.array(results['detection_boxes']),\r\n",
        "    np.array(results['detection_classes']),\r\n",
        "    np.array(results['detection_scores']),\r\n",
        "    category_index,\r\n",
        "    instance_masks=results.get('detection_masks'),\r\n",
        "    use_normalized_coordinates=True,\r\n",
        "    line_thickness=8)\r\n",
        "\r\n",
        "plt.figure(figsize=(24, 16))\r\n",
        "plt.imshow(image_np)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}