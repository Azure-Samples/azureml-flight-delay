{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Flight Delay Demo - MLOps with MLflow\n",
        "\n",
        "## Install prerequisites\n",
        "\n",
        "Before running the notebook, make sure the correct versions of these libraries are installed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install --upgrade mlflow azureml-mlflow azureml-core"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Datasheets\r\n",
        "\r\n",
        "Define helper functions to enable model data sheets."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from markdown import markdown\r\n",
        "\r\n",
        "def get_tag(tagname):\r\n",
        "    text = ''\r\n",
        "    try:\r\n",
        "        text = tags[tagname]\r\n",
        "    except:\r\n",
        "        print('Missing tag ' + tagname)\r\n",
        "    finally:\r\n",
        "        return text\r\n",
        "\r\n",
        "def get_datasheet(tags):\r\n",
        "    title = get_tag('title')\r\n",
        "    description = get_tag('datasheet_description')\r\n",
        "    details = get_tag('details')\r\n",
        "    date = get_tag('date')\r\n",
        "    modeltype = get_tag('type')\r\n",
        "    version = get_tag('version')\r\n",
        "    helpresources = get_tag('help')\r\n",
        "    usecase_primary = get_tag('usecase_primary')\r\n",
        "    usecase_secondary = get_tag('usecase_secondary')\r\n",
        "    usecase_outofscope = get_tag('usecase_outofscope')\r\n",
        "    dataset_description = get_tag('dataset_description')\r\n",
        "    motivation = get_tag('motivation')\r\n",
        "    caveats = get_tag('caveats')\r\n",
        "\r\n",
        "    datasheet = ''\r\n",
        "    datasheet+=markdown(f'# {title} \\n {description} \\n')\r\n",
        "    datasheet+=markdown(f'## Model Details \\n {details} \\n')\r\n",
        "    datasheet+=markdown(f'### Model date \\n {date} \\n')\r\n",
        "    datasheet+=markdown(f'### Model type \\n {modeltype} \\n')\r\n",
        "    datasheet+=markdown(f'### Model version \\n {version} \\n')\r\n",
        "    datasheet+=markdown(f'### Where to send questions or comments about the model \\n Please send questions or concerns using [{helpresources}]({helpresources}) \\n')\r\n",
        "    datasheet+=markdown('## Intended Uses:\\n')\r\n",
        "    datasheet+=markdown(f'### Primary use case \\n {usecase_primary} \\n')\r\n",
        "    datasheet+=markdown(f'### Secondary use case \\n {usecase_secondary} \\n')\r\n",
        "    datasheet+=markdown(f'### Out of scope \\n {usecase_outofscope} \\n')\r\n",
        "    datasheet+=markdown('## Evaluation Data:\\n')\r\n",
        "    datasheet+=markdown(f'### Datasets \\n {dataset_description} \\n')\r\n",
        "    datasheet+=markdown(f'### Motivation \\n {motivation} \\n')\r\n",
        "    datasheet+=markdown(f'### Caveats \\n {caveats} \\n')\r\n",
        "\r\n",
        "    return datasheet"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "import logging\r\n",
        "logging.basicConfig(level = logging.ERROR)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup working directory\n",
        "\n",
        "The cell below creates our working directory. This will hold our generated scripts."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "\r\n",
        "project_folder = './scripts'\r\n",
        "\r\n",
        "# Working directory\r\n",
        "if not os.path.exists(project_folder):\r\n",
        "    os.makedirs(project_folder)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Script\n",
        "\n",
        "Let's write our training script to the working directory.\n",
        "\n",
        "The `sklearn.preprocessing.LabelEncoder` encodes target labels with value between 0 and n_classes-1.\n",
        "\n",
        "The `sklearn.model_selection.train_test_split` splits arrays or matrices into random train and test subsets\n",
        "\n",
        "The `sklearn.metrics.accuracy_score` is an accuracy classification score. In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\n",
        "\n",
        "The `sklearn.metrics.confusion_matrix` is compute confusion matrix to evaluate the accuracy of a classification.\n",
        "\n",
        "The `sklearn.metrics.f1_score` computes the F1 score, also known as balanced F-score or F-measure. The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
        "\n",
        "The `sklearn.metrics.precision_score` computes the precision. The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives.\n",
        "\n",
        "The `sklearn.metrics.recall_score` computes the recall. The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
        "\n",
        "The `sklearn.metrics.roc_auc_score` computes Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
        "\n",
        "The `sklearn.metrics.roc_curve` computes Receiver operating characteristic (ROC).\n",
        "\n",
        "The `Model Class` represents the result of machine learning training. A model is the result of a Azure Machine learning training Run or some other model training process outside of Azure. Regardless of how the model is produced, it can be registered in a workspace, where it is represented by a name and a version. \n",
        "\n",
        "\n",
        "For more information on **Model Class**, please visit: [Microsoft Model Class Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile $project_folder/utils.py\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import seaborn as sns\r\n",
        "from azureml.core import Model\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\r\n",
        "from azureml.core import Dataset\r\n",
        "from azureml.core import Model, Run, Workspace\r\n",
        "import mlflow\r\n",
        "from mlflow.utils.file_utils import TempDir\r\n",
        "\r\n",
        "def split_dataset(X_raw, Y):\r\n",
        "    A = X_raw[['UniqueCarrier']]\r\n",
        "    X = X_raw.drop(labels=['UniqueCarrier'],axis = 1)\r\n",
        "    X = pd.get_dummies(X)\r\n",
        "\r\n",
        "\r\n",
        "    le = LabelEncoder()\r\n",
        "    Y = le.fit_transform(Y)\r\n",
        "\r\n",
        "    X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(X_raw, \r\n",
        "                                                        Y, \r\n",
        "                                                        A,\r\n",
        "                                                        test_size = 0.2,\r\n",
        "                                                        random_state=123,\r\n",
        "                                                        stratify=Y)\r\n",
        "\r\n",
        "    # Work around indexing bug\r\n",
        "    X_train = X_train.reset_index(drop=True)\r\n",
        "    A_train = A_train.reset_index(drop=True)\r\n",
        "    X_test = X_test.reset_index(drop=True)\r\n",
        "    A_test = A_test.reset_index(drop=True)\r\n",
        "\r\n",
        "    return X_train, X_test, Y_train, Y_test, A_train, A_test \r\n",
        "\r\n",
        "def prepareDataset(X_raw):\r\n",
        "    df = X_raw.to_pandas_dataframe()\r\n",
        "    Y = df['ArrDelay15'].values\r\n",
        "    synth_df = df.drop(columns=['ArrDelay15'])\r\n",
        "    return synth_df, Y\r\n",
        "\r\n",
        "def analyze_model(clf, X_test, Y_test, preds):\r\n",
        "    ws = Workspace.from_config()\r\n",
        "\r\n",
        "    mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\r\n",
        "    experiment_name = 'flight_delay_with_mlflow'\r\n",
        "    mlflow.set_experiment(experiment_name)\r\n",
        "\r\n",
        "    with mlflow.start_run() as run:\r\n",
        "        accuracy = accuracy_score(Y_test, preds)\r\n",
        "        print(f'Accuracy', np.float(accuracy))\r\n",
        "        mlflow.log_metric(f'Accuracy', np.float(accuracy))\r\n",
        "\r\n",
        "        precision = precision_score(Y_test, preds, average=\"macro\")\r\n",
        "        print(f'Precision', np.float(precision))\r\n",
        "        mlflow.log_metric(f'Precision', np.float(precision))\r\n",
        "        \r\n",
        "        recall = recall_score(Y_test, preds, average=\"macro\")\r\n",
        "        print(f'Recall', np.float(recall))\r\n",
        "        mlflow.log_metric(f'Recall', np.float(recall))\r\n",
        "        \r\n",
        "        f1score = f1_score(Y_test, preds, average=\"macro\")\r\n",
        "        print(f'F1 Score', np.float(f1score))\r\n",
        "        mlflow.log_metric(f'F1 Score', np.float(f1score))\r\n",
        "        \r\n",
        "        with TempDir() as tmp:\r\n",
        "            local_path = tmp.path(\"model\")\r\n",
        "            mlflow.sklearn.save_model(clf, path=local_path)\r\n",
        "\r\n",
        "            # Workaround a bug where scikit-learn requirement isn't correct\r\n",
        "            data = ''\r\n",
        "            with open(os.path.join(local_path, 'requirements.txt'), 'r') as infile:\r\n",
        "                data = infile.read().replace('scikit-learn==0.0\\n', '')\r\n",
        "            with open(os.path.join(local_path, 'requirements.txt'), 'w') as outfile:\r\n",
        "                outfile.write(data)\r\n",
        "            with open(os.path.join(local_path, 'conda.yaml'), 'r') as infile:\r\n",
        "                data = infile.read().replace('  - scikit-learn==0.0\\n', '')\r\n",
        "            with open(os.path.join(local_path, 'conda.yaml'), 'w') as outfile:\r\n",
        "                outfile.write(data)\r\n",
        "            # End workaround\r\n",
        "\r\n",
        "            mlflow.log_artifact(local_path)\r\n",
        "\r\n",
        "        class_names = clf.classes_\r\n",
        "        fig, ax = plt.subplots()\r\n",
        "        tick_marks = np.arange(len(class_names))\r\n",
        "        plt.xticks(tick_marks, class_names)\r\n",
        "        plt.yticks(tick_marks, class_names)\r\n",
        "        sns.heatmap(pd.DataFrame(confusion_matrix(Y_test, preds)), annot=True, cmap='YlGnBu', fmt='g')\r\n",
        "        ax.xaxis.set_label_position('top')\r\n",
        "        plt.tight_layout()\r\n",
        "        plt.title('Confusion Matrix', y=1.1)\r\n",
        "        plt.ylabel('Actual label')\r\n",
        "        plt.xlabel('Predicted label')\r\n",
        "        plt.show()\r\n",
        "        fig.savefig(\"ConfusionMatrix.png\")\r\n",
        "        mlflow.log_artifact(\"ConfusionMatrix.png\")\r\n",
        "        plt.close()\r\n",
        "\r\n",
        "        preds_proba = clf.predict_proba(X_test)[::,1]\r\n",
        "        fpr, tpr, _ = roc_curve(Y_test, preds_proba, pos_label = clf.classes_[1])\r\n",
        "        auc = roc_auc_score(Y_test, preds_proba)\r\n",
        "        plt.plot(fpr, tpr, label=\"data 1, auc=\" + str(auc))\r\n",
        "        plt.legend(loc=4)\r\n",
        "        plt.show()\r\n",
        "        plt.close()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Workspace\n",
        "\n",
        "In the next cell, we create a new Workspace config object using the `<subscription_id>`, `<resource_group_name>`, and `<workspace_name>`. This will fetch the matching Workspace and prompt you for authentication. Please click on the link and input the provided details.\n",
        "\n",
        "For more information on **Workspace**, please visit: [Microsoft Workspace Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py)\n",
        "\n",
        "`<subscription_id>` = You can get this ID from the landing page of your Resource Group.\n",
        "\n",
        "`<resource_group_name>` = This is the name of your Resource Group.\n",
        "\n",
        "`<workspace_name>` = This is the name of your Workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.workspace import Workspace\r\n",
        "\r\n",
        "try:    \r\n",
        "    # Get instance of the Workspace and write it to config file\r\n",
        "    ws = Workspace(\r\n",
        "        subscription_id = '<subscription_id>', \r\n",
        "        resource_group = '<resource_group>', \r\n",
        "        workspace_name = '<workspace_name>')\r\n",
        "\r\n",
        "    # Writes workspace config file\r\n",
        "    ws.write_config()\r\n",
        "    \r\n",
        "    print('Library configuration succeeded')\r\n",
        "except Exception as e:\r\n",
        "    print(e)\r\n",
        "    print('Workspace not found')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Drift\n",
        "\n",
        "Data drift is one of the top reasons model accuracy degrades over time. For machine learning models, data drift is the change in model input data that leads to model performance degradation. Monitoring data drift helps detect these model performance issues.\n",
        "\n",
        "Causes of data drift include:\n",
        "\n",
        "* Upstream process changes, such as a sensor being replaced that changes the units of measurement from inches to centimeters.\n",
        "* Data quality issues, such as a broken sensor always reading 0.\n",
        "* Natural drift in the data, such as mean temperature changing with the seasons.\n",
        "* Change in relation between features, or covariate shift."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset\n",
        "\n",
        "First step is to get our data using Dataset, the function `Dataset.get_by_name()` returns a registered Dataset from a given `workspace` and its registration `name`.\n",
        "\n",
        "`workspace` = The existing AzureML workspace in which the Dataset was registered..\n",
        "\n",
        "`name` = The registration name.\n",
        "\n",
        "`dataframe.take() ` = Function returns the elements in the given positional indices along an axis. \n",
        "\n",
        "For more information on **Dataset**, please visit: [Microsoft Dataset Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py#get-by-name-workspace--name--version--latest--)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Dataset, Datastore\n",
        "\n",
        "tabular = Dataset.get_by_name(ws, 'flightdelayweather_ds')\n",
        "\n",
        "data = tabular.to_pandas_dataframe()\n",
        "tabular.take(3).to_pandas_dataframe()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create AML Compute Cluster\n",
        "\n",
        "Firstly, check for the existence of the cluster. If it already exists, we are able to reuse it. Checking for the existence of the cluster can be performed by calling the constructor `ComputeTarget()` with the current workspace and name of the cluster.\n",
        "\n",
        "In case the cluster does not exist, the next step will be to provide a configuration for the new AML cluster by calling the function `AmlCompute.provisioning_configuration()`. It takes as parameters the VM size and the max number of nodes that the cluster can scale up to. After the configuration has executed, `ComputeTarget.create()` should be called with the previously configuration object and the workspace object.\n",
        "\n",
        "For more information on **ComputeTarget**, please visit: [Microsoft ComputeTarget Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computetarget?view=azure-ml-py)\n",
        "\n",
        "For more information on **AmlCompute**, please visit: [Microsoft AmlCompute Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.akscompute?view=azure-ml-py)\n",
        "\n",
        "\n",
        "**Note:** Please wait for the execution of the cell to finish before moving forward."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "### Create AML CPU Compute Cluster\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name='cpucluster')\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_v2',\n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, 'cpucluster', compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create baseline for Data Drift Monitor\n",
        "\n",
        "Specify a baseline dataset - usually the training dataset for a model. A target dataset - usually model input data - is compared over time to your baseline dataset.\n",
        "\n",
        "The `from_delimited_files` creates a TabularDataset to represent tabular data in delimited files (e.g. CSV and TSV).\n",
        "\n",
        "The `with_timestamp_columns` defines timestamp columns for the dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_drift = tabular.to_pandas_dataframe()\n",
        "data_drift.dropna()\n",
        "data_drift['Date'] = pd.to_datetime(dict(year=2008, month=data_drift.Month, day=data_drift.DayofMonth), errors='coerce')\n",
        "data_drift = data_drift[data_drift['Date'].notna()]\n",
        "file_name = 'flight_delay_ds_wDate.csv'\n",
        "data_drift.to_csv(file_name, index=False)\n",
        "data_store = Datastore.get_default(ws)\n",
        "data_store.upload_files(['../flight-delay-mlops/' + file_name], overwrite=True)\n",
        "datastore_path = [(data_store, file_name)]\n",
        "\n",
        "drift_tabular = Dataset.Tabular.from_delimited_files(datastore_path)\n",
        "\n",
        "# assign the timestamp attribute to a real or virtual column in the dataset\n",
        "drift_tabular = drift_tabular.with_timestamp_columns('Date')\n",
        "\n",
        "drift_tabular = drift_tabular.register(workspace=ws,\n",
        "                           name='target',\n",
        "                           create_new_version=True)\n",
        "\n",
        "drift_tabular.take(3).to_pandas_dataframe()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Data Drift Monitor\n",
        "\n",
        "The DataDriftDetector class enables you to configure a data monitor object which then can be run as a job to analyze data drift. Data drift jobs can be run interactively or enabled to run on a schedule. \n",
        "\n",
        "The `get_by_name` retrieves a unique DataDriftDetector object for a given workspace and name.\n",
        "\n",
        "The `create_from_datasets` creates a new DataDriftDetector object from a baseline tabular dataset and a target time series dataset.\n",
        "\n",
        "For more information on **DataDriftDetector Class**, please visit: [Microsoft DataDriftDetector Class Documentation](https://docs.microsoft.com/en-us/python/api/azureml-datadrift/azureml.datadrift.datadriftdetector.datadriftdetector?view=azure-ml-py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.datadrift import DataDriftDetector\n",
        "from datetime import datetime\n",
        "\n",
        "target = Dataset.get_by_name(ws, 'target')\n",
        "\n",
        "# set the baseline dataset\n",
        "baseline = target.time_before(datetime(2008, 4, 1))\n",
        "\n",
        "try:\n",
        "    # get data drift detector by name\n",
        "    monitor = DataDriftDetector.get_by_name(ws, 'fd-drift-monitor')\n",
        "except:\n",
        "    # set up data drift detector\n",
        "    monitor = DataDriftDetector.create_from_datasets(ws, 'fd-drift-monitor', baseline, target, \n",
        "                                                          compute_target=compute_target, \n",
        "                                                          frequency='Week', \n",
        "                                                          feature_list=None, \n",
        "                                                          drift_threshold=0.6, \n",
        "                                                          latency=24)\n",
        "\n",
        "\n",
        "\n",
        "columns  = list(baseline.take(1).to_pandas_dataframe())\n",
        "exclude  = ['Month', 'DayofMonth', 'DayofWeek','Origin_dayl', 'Dest_dayl', 'Origin_srad', 'Dest_srad', 'Origin_swe', 'Dest_swe', 'Origin_tmax', 'Dest_tmax', 'Origin_tmin', 'Dest_tmin', 'Origin_vp', 'Dest_vp', '__index_level_0__']\n",
        "features = [col for col in columns if col not in exclude]\n",
        "\n",
        "# update data drift detector\n",
        "monitor = monitor.update(feature_list=features)\n",
        "\n",
        "backfill = monitor.backfill(datetime(2008, 4, 1), datetime(2008, 6, 1))\n",
        "\n",
        "backfill.wait_for_completion(show_output=False, wait_post_processing=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze historical data and backfill\n",
        "\n",
        "See how the dataset differs from the target dataset in the specified time period. The closer to 100%, the more the two datasets differ."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get results from Python SDK (wait for backfills or monitor runs to finish)\n",
        "results, metrics = monitor.get_output(start_time=datetime(year=2008, month=4, day=1))\n",
        "# plot the results from Python SDK \n",
        "monitor.show(datetime(2008, 4, 1), datetime(2008, 6, 1))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Register\n",
        "\n",
        "## Load Dataset\n",
        "\n",
        "First step is to get our data using Dataset, the function `Dataset.get_by_name()` returns a registered Dataset from a given `workspace` and its registration `name`.\n",
        "\n",
        "`workspace` = The existing AzureML workspace in which the Dataset was registered..\n",
        "\n",
        "`name` = The registration name.\n",
        "\n",
        "`dataframe.take() ` = Function returns the elements in the given positional indices along an axis. \n",
        "\n",
        "For more information on **Dataset**, please visit: [Microsoft Dataset Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py#get-by-name-workspace--name--version--latest--)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Dataset\r\n",
        "\r\n",
        "tabular = Dataset.get_by_name(ws, 'flightdelayweather_ds_clean')\r\n",
        "\r\n",
        "data = tabular.to_pandas_dataframe()\r\n",
        "tabular.take(3).to_pandas_dataframe()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with sklearn\n",
        "\n",
        "The `Pipeline()` function purpose is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "\n",
        "The `sklearn.linear_model.LogisticRegression` class implements regularized logistic regression using the ‘liblinear’ library, ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ solvers.\n",
        "\n",
        "The `sklearn.preprocessing.StandardScaler()` function standardizes features by removing the mean and scaling to unit variance."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from azureml.core import Dataset, Run\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scripts.utils import *\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Fetch dataset from the run by name\n",
        "synth_df, Y = prepareDataset(tabular)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, Y_train, Y_test, A_train, A_test = split_dataset(synth_df, Y)\n",
        "\n",
        "# Setup scikit-learn pipeline\n",
        "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "\n",
        "clf = Pipeline(steps=[('classifier', LogisticRegression(solver='liblinear', fit_intercept=True))])\n",
        "\n",
        "\n",
        "model = clf.fit(X_train, Y_train)\n",
        "preds = clf.predict(X_test)\n",
        "analyze_model(clf, X_test, Y_test, preds)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch latest model\n",
        "\n",
        "Let's fetch the latest run for our experiment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Run, Experiment\r\n",
        "exp = Experiment(ws, 'flight_delay_with_mlflow')\r\n",
        "run = next(exp.get_runs())\r\n",
        "run"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment\r\n",
        "\r\n",
        "MLflow provides native support for AKS and ACI deployment options.\r\n",
        "\r\n",
        "## Deploy to Azure Kubernetes Service (AKS)\r\n",
        "To deploy your MLflow model to an Azure Machine Learning web service, your model must be set up with the MLflow Tracking URI to connect with Azure Machine Learning.\r\n",
        "\r\n",
        "To deploy to AKS, first create an AKS cluster. Create an AKS cluster using the ComputeTarget.create() method. It may take 20-25 minutes to create a new cluster."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.compute import AksCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "\n",
        "prov_config = AksCompute.provisioning_configuration(location='westus2')\n",
        "\n",
        "try:\n",
        "    aks_target = AksCompute(ws, 'flight-delay-aks')\n",
        "except ComputeTargetException:\n",
        "    # Create the cluster\n",
        "    aks_target = ComputeTarget.create(workspace = ws, \n",
        "                            name = 'flight-delay-aks', \n",
        "                            provisioning_configuration = prov_config)\n",
        "    aks_target.wait_for_completion(True)\n",
        "\n",
        "print(aks_target.provisioning_state)\n",
        "print(aks_target.provisioning_errors)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, register and deploy the model in one step with MLflow's deployment client."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from mlflow.deployments import get_deploy_client\n",
        "import json",
        "\n",
        "deployment_config = {\"computeType\": \"aks\", \"computeTargetName\": \"flight-delay-aks\"}\n",
        "\n",
        "with open('deployment_config.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(deployment_config, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# set the tracking uri as the deployment client\n",
        "client = get_deploy_client(mlflow.get_tracking_uri())\n",
        "\n",
        "# set the model path \n",
        "model_path = \"model\"\n",
        "\n",
        "# set the deployment config\n",
        "deploy_path = \"deployment_config.json\"\n",
        "test_config = {'deploy-config-file': deploy_path}\n",
        "\n",
        "# define the model path and the name is the service name\n",
        "# the model gets registered automatically and a name is autogenerated using the \"name\" parameter below \n",
        "client.create_deployment(model_uri='runs:/{}/{}'.format(run.id, model_path),\n",
        "                         config=test_config,\n",
        "                         name=\"fd-delay-mlflow-aks\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy to Azure Container Instance (ACI)\n",
        "\n",
        "The `mlflow.tracking.MlflowClient` class is a client of an MLflow Tracking Server that creates and manages experiments and runs, and of an MLflow Registry Server that creates and manages registered models and model versions.\n",
        "\n",
        "The `get_deploy_client` function returns a subclass of `mlflow.deployments.BaseDeploymentClient` exposing standard APIs for deploying models to the specified target."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import mlflow.azureml\n",
        "from azureml.core.webservice import Webservice\n",
        "from mlflow.deployments import get_deploy_client\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# set the tracking uri as the deployment client\n",
        "client = get_deploy_client(mlflow.get_tracking_uri())\n",
        "\n",
        "# set the model path \n",
        "model_path = \"model\"\n",
        "\n",
        "# define the model path and the name is the service name\n",
        "# the model gets registered automatically and a name is autogenerated using the \"name\" parameter below \n",
        "client.create_deployment(model_uri='runs:/{}/{}'.format(run.id, model_path),\n",
        "                         name=\"fd-mlflow-aci\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to deployed webservice\n",
        "\n",
        "Now with test data, we can get it into a suitable format to consume the web service. First an instance of the web service should be obtained by calling the constructor `Webservice()` with the Workspace object and the service name as parameters. Sanitizing of the data is then performed in order to avoid sending unexpected columns to the web service. Finally, call the service via POST using the `requests` module. `requests.post()` will call the deployed web service. It takes for parameters the service URL, the test data, and a headers dictionary that contains the authentication token.\n",
        "\n",
        "For more information on **Webservice**, please visit: [Microsoft Webservice Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice?view=azure-ml-py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import json\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from azureml.core.webservice import Webservice\r\n",
        "\r\n",
        "aks_service = Webservice(ws, 'fd-mlflow-aks')\r\n",
        "\r\n",
        "# prepare the test data\r\n",
        "sample = data.drop(columns=['ArrDelay15']).sample(n=10, random_state=4).values.tolist()\r\n",
        "\r\n",
        "headers = {'Content-Type':'application/json'}\r\n",
        "\r\n",
        "if aks_service.auth_enabled:\r\n",
        "    headers['Authorization'] = 'Bearer '+ aks_service.get_keys()[0]\r\n",
        "\r\n",
        "output_df = []\r\n",
        "for x in sample:    \r\n",
        "    test_sample = json.dumps({'input_data': {'data': [x]}})\r\n",
        "    response = requests.post(aks_service.scoring_uri + '?verbose=true', data=test_sample, headers=headers)\r\n",
        "    prediction = [bool(response.json()[0])]\r\n",
        "    prediction.extend(x)\r\n",
        "    output_df.append(prediction)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Present scoring service predictions\r\n",
        "\r\n",
        "Let's format our service responses and present them in a suitable way to our end users."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def highlight_delays(val):\n",
        "    return 'background-color: yellow' if val == True else ''\n",
        "\n",
        "predictions = pd.DataFrame(output_df, columns =['Prediction', 'Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime', 'UniqueCarrier', 'CRSElapsedTime', 'Origin', 'Dest', 'Distance', 'Origin_Lat', 'Origin_Lon', 'Origin_State', 'Dest_Lat', 'Dest_Lon', 'Dest_State', 'Origin_dayl', 'Dest_dayl', 'Origin_prcp', 'Dest_prcp', 'Origin_srad', 'Dest_srad', 'Origin_swe', 'Dest_swe', 'Origin_tmax', 'Dest_tmax', 'Origin_tmin', 'Dest_tmin', 'Origin_vp', 'Dest_vp'])\n",
        "predictions = predictions.style.applymap(highlight_delays, subset=['Prediction'])\n",
        "predictions"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629237818264
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Deploy to Managed Endpoints\n",
        "\n",
        "While the MLflow SDK does not provide out-of-the-box support for managed endpoints, it's easy to deploy OSS models to this service.\n",
        "\n",
        "First, create a new directory to hold the configuration files for deploying a managed endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "\n",
        "managed_endpoints = './managed-endpoints'\n",
        "\n",
        "# Working directory\n",
        "if not os.path.exists(managed_endpoints):\n",
        "    os.makedirs(managed_endpoints)\n",
        "    \n",
        "if os.path.exists(os.path.join(managed_endpoints,\".amlignore\")):\n",
        "  os.remove(os.path.join(managed_endpoints,\".amlignore\"))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Create Scoring File\n",
        "\n",
        "Creating the scoring file is next step before deploying the service. This file is responsible for the actual generation of predictions using the model. The values or scores generated can represent predictions of future values, but they might also represent a likely category or outcome.\n",
        "\n",
        "The first thing to do in the scoring file is to fetch the model. This is done by calling `Model.get_model_path()` and passing the model name as a parameter.\n",
        "\n",
        "After the model has been loaded, the function `model.predict()` function should be called to start the scoring process.\n",
        "\n",
        "For more information on **Machine Learning - Score**, please visit: [Microsoft Machine Learning - Score Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/machine-learning-score)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile $managed_endpoints/score.py\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import azureml.automl.core\n",
        "from sklearn.externals import joblib\n",
        " \n",
        "def init():\n",
        "    global model\n",
        "    print (\"model initialized\" + time.strftime(\"%H:%M:%S\"))\n",
        "    \n",
        "    # this name is model.id of model that we want to deploy\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"model/model.pkl\")\n",
        "    \n",
        "    # deserialize the model file back into a sklearn model\n",
        "    model = joblib.load(model_path)\n",
        "    \n",
        "def run(data):\n",
        "    try:\n",
        "        data = json.loads(data)\n",
        "        df = pd.DataFrame(data['data'], columns=['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime',\n",
        "       'UniqueCarrier', 'CRSElapsedTime', 'Origin', 'Dest', 'Distance',\n",
        "       'Origin_Lat', 'Origin_Lon', 'Origin_State', 'Dest_Lat', 'Dest_Lon',\n",
        "       'Dest_State', 'Origin_dayl', 'Dest_dayl', 'Origin_prcp', 'Dest_prcp',\n",
        "       'Origin_srad', 'Dest_srad', 'Origin_swe', 'Dest_swe', 'Origin_tmax',\n",
        "       'Dest_tmax', 'Origin_tmin', 'Dest_tmin', 'Origin_vp', 'Dest_vp']) \n",
        "        result = model.predict(df)\n",
        "    except Exception as e:\n",
        "        result = str(e)\n",
        "        print(result)\n",
        "        return {\"error\": result}\n",
        "    return {\"result\":result.tolist()}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Create the environment definition\n",
        "\n",
        "The following file contains the details of the environment to host the model and code. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile $managed_endpoints/score-new.yml\n",
        "name: fd-mlflow-mng-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.7\n",
        "  - numpy\n",
        "  - pip\n",
        "  - scikit-learn==0.22.1\n",
        "  - scipy\n",
        "  - pip:\n",
        "    - azureml-defaults\n",
        "    - azureml-sdk[notebooks,automl]\n",
        "    - pandas\n",
        "    - inference-schema[numpy-support]\n",
        "    - joblib\n",
        "    - numpy\n",
        "    - scipy"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Define the endpoint configuration\n",
        "Specific inputs are required to deploy a model on an online endpoint:\n",
        "\n",
        "1. Model files.\n",
        "1. The code that's required to score the model.\n",
        "1. An environment in which your model runs.\n",
        "1. Settings to specify the instance type and scaling capacity."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile $managed_endpoints/endpointconfig.yml\r\n",
        "name: fd-mlflow-mng-endpoint\r\n",
        "type: online\r\n",
        "auth_mode: key\r\n",
        "traffic:\r\n",
        "  blue: 100\r\n",
        "\r\n",
        "deployments:\r\n",
        "  #blue deployment\r\n",
        "  - name: blue\r\n",
        "    model: azureml:fd-mlflow-aks-model:1\r\n",
        "    code_configuration:\r\n",
        "      code:\r\n",
        "        local_path: ./\r\n",
        "      scoring_script: score.py\r\n",
        "    environment: \r\n",
        "      name: fd-mlflow-mng-env\r\n",
        "      version: 1\r\n",
        "      path: ./\r\n",
        "      conda_file: file:./score-new.yml\r\n",
        "      docker:\r\n",
        "          image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210727.v1\r\n",
        "    instance_type: Standard_DS3_v2\r\n",
        "    scale_settings:\r\n",
        "      scale_type: manual\r\n",
        "      instance_count: 1\r\n",
        "      min_instances: 1\r\n",
        "      max_instances: 2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Deploy your managed online endpoint to Azure\n",
        "\n",
        "This deployment might take up to 15 minutes, depending on whether the underlying environment or image is being built for the first time. Subsequent deployments that use the same environment will finish processing more quickly."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!az ml endpoint create -g [your resource group name] -w [your AML workspace name] -n fd-mlflow-mng-endpoint -f ./managed-endpoints/endpointconfig.yml"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Generate a sample request JSON file\n",
        "\n",
        "Export some test data to a JSON file we can send to the endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile $managed_endpoints/sample-request.json\n",
        "{\"data\": [\n",
        "[6.0,21.0,6.0,1330.0,1600.0,9.0,150.0,16.0,93.0,745.0,33.64044444,-84.42694444,8.0,40.69249722,-74.16866056,29.0,51148.8,53568.0,2.0,0.0,438.4,451.2,0.0,0.0,30.5,28.5,18.0,15.0,2040.0,1720.0],\n",
        "[4.0,2.0,3.0,1910.0,2035.0,11.0,85.0,222.0,62.0,361.0,35.87763889,-78.78747222,25.0,39.99798528,-82.89188278,33.0,44928.0,45273.6,0.0,0.0,355.2,438.4,0.0,0.0,23.0,12.5,12.0,1.5,1400.0,680.0],\n",
        "[1.0,3.0,4.0,935.0,1224.0,16.0,229.0,207.0,78.0,1302.0,39.87195278,-75.24114083,36.0,32.89595056,-97.0372,41.0,33177.6,35596.8,0.0,0.0,156.8,252.8,0.0,0.0,-2.0,6.5,-8.0,-4.5,320.0,440.0],\n",
        "[4.0,3.0,4.0,1000.0,1252.0,16.0,172.0,207.0,206.0,951.0,39.87195278,-75.24114083,36.0,26.68316194,-80.09559417,7.0,45273.6,44582.4,0.0,4.0,425.6,220.8,0.0,0.0,12.0,28.0,0.5,22.5,640.0,2720.0],\n",
        "[1.0,21.0,1.0,800.0,1045.0,15.0,105.0,198.0,129.0,589.0,41.979595,-87.90446417,12.0,38.94453194,-77.45580972,43.0,33868.8,34905.6,2.0,0.0,256.0,246.4,56.0,0.0,-7.0,-3.0,-17.0,-13.5,160.0,200.0],\n",
        "[3.0,12.0,3.0,1640.0,1952.0,5.0,192.0,89.0,101.0,1065.0,40.69249722,-74.16866056,29.0,26.07258333,-80.15275,7.0,41817.6,42508.8,0.0,0.0,336.0,368.0,0.0,0.0,10.0,27.0,0.5,19.5,640.0,2280.0],\n",
        "[3.0,19.0,3.0,1229.0,1346.0,6.0,77.0,151.0,76.0,214.0,40.77724306,-73.87260917,32.0,38.85208333,-77.03772222,43.0,42854.4,42854.4,22.0,0.0,204.8,307.2,0.0,0.0,10.0,15.0,4.0,6.5,800.0,960.0],\n",
        "[4.0,18.0,5.0,1210.0,1503.0,4.0,173.0,139.0,169.0,944.0,40.63975111,-73.77892556,32.0,28.42888889,-81.31602778,7.0,47692.8,45964.8,0.0,0.0,524.8,508.8,0.0,0.0,22.5,26.0,5.5,11.5,920.0,1360.0],\n",
        "[11.0,1.0,6.0,615.0,745.0,9.0,90.0,130.0,18.0,432.0,39.71732917,-86.29438417,13.0,33.64044444,-84.42694444,8.0,36633.6,38016.0,0.0,0.0,297.6,387.2,0.0,0.0,22.0,20.5,5.0,2.0,880.0,720.0],\n",
        "[11.0,24.0,1.0,936.0,1123.0,8.0,107.0,208.0,77.0,602.0,33.43416667,-112.00805559999999,3.0,39.85840806,-104.6670019,5.0,35942.4,34214.4,0.0,0.0,297.6,291.2,0.0,0.0,27.5,17.0,10.0,-9.5,520.0,280.0]]}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Invoke the endpoint to score data by using your model\n",
        "\n",
        "You can use either the invoke command or a REST client of your choice to invoke the endpoint and score against it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!az ml endpoint invoke -g [your resource group name] -w [your AML workspace name] -n fd-mlflow-mng-endpoint --request-file ./managed-endpoints/sample-request.json"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traceability\r\n",
        "\r\n",
        "## Update Model\r\n",
        "\r\n",
        "We can update the model registered during deployment with additional metadata, including the linked dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "model = Model(ws, 'fd-mlflow-aks-model')\r\n",
        "model.update(description='This model was developed by Microsoft to showcase the capabilities of Azure ML.',\r\n",
        "             tags={'title': 'Flight Delay Model',\r\n",
        "    'datasheet_description':\r\n",
        "\"\"\"\r\n",
        "Last updated: October 2020\r\n",
        "\r\n",
        "Based on dataset from by [Statistical Computing Statistical Graphics](http://stat-computing.org/dataexpo/2009/the-data.html)\r\n",
        "\r\n",
        "\"\"\",\r\n",
        "    'details': 'This model was developed for Microsoft.',\r\n",
        "    'date': 'October 2020, trained on data that cuts off at the end of 2008.', \r\n",
        "    'type': 'Classification model',\r\n",
        "    'version': '1.0',\r\n",
        "    'help': 'https://www.azure.com/',\r\n",
        "    'usecase_primary': \r\n",
        "\"\"\"\r\n",
        "Developed for Flight Delay Demo.\r\n",
        "\r\n",
        "\"\"\",\r\n",
        "    'usecase_secondary':\r\n",
        "\"\"\"\r\n",
        "Field demos and marketing.\r\n",
        "\r\n",
        "\"\"\",\r\n",
        "    'usecase_outofscope':\r\n",
        "\"\"\"\r\n",
        "Do not use for production environments.\r\n",
        "\r\n",
        "\"\"\",\r\n",
        "    'dataset_description':\r\n",
        "\"\"\"\r\n",
        "The data comes originally from RITA where it is described in detail. You can download the data there, or from the bzipped csv files listed below. These files have derivable variables removed, are packaged in yearly chunks and have been more heavily compressed than the originals.\r\n",
        "\r\n",
        "\"\"\",\r\n",
        "    'motivation': 'Demo the main features behind the Azure ML Workspace environment',\r\n",
        "    'caveats':\r\n",
        "\"\"\"\r\n",
        "\"\"\"})\r\n",
        "\r\n",
        "model.add_dataset_references([(Dataset.Scenario.TRAINING, tabular)])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trace back to model dataset\r\n",
        "\r\n",
        "Dataset instance associated with the registered model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pd.DataFrame(\r\n",
        "    {'Dataset Id': model.datasets['training'][0].id,\r\n",
        "     'Name': model.datasets['training'][0].name }, index=[0])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Datasheet\r\n",
        "\r\n",
        "Datasheet associated with the registered model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from IPython.core.display import display,Markdown\r\n",
        "\r\n",
        "tags = model.tags\r\n",
        "display(Markdown(get_datasheet(tags)))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projects\n",
        "\n",
        "## Set tracking URI to Azure ML\n",
        "\n",
        "The `mlflow.tracking` module provides a Python CRUD interface to MLflow experiments and runs. \n",
        "\n",
        "We update tracking URI via `set_tracking_uri()` function."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "import mlflow.azureml\n",
        "import mlflow\n",
        "\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623347089992
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure the active experiment\n",
        "\n",
        "The `mlflow.set_experiment()` function sets an experiment as active. If the experiment does not exist, creates a new experiment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "experiment_name = \"fs_with_mlflow_proj\"\n",
        "mlflow.set_experiment(experiment_name)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623347092345
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute the project run\n",
        "\n",
        "The `mlflow.projects.run()` function allows us to run an MLflow project. The project can be local or stored at a Git URI."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "backend_config = {\"USE_CONDA\": True}\n",
        "local_mlproject_run = mlflow.projects.run(uri=\".\", backend = \"azureml\", backend_config = backend_config)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Portal\r\n",
        "\r\n",
        "## Start MLflow portal\r\n",
        "\r\n",
        "By starting the MLflow portal with the Azure ML tracking URI, we can use the MLflow experiments UI to explore data stored in Azure ML."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tracking_uri = ws.get_mlflow_tracking_uri()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install mlflow"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!mlflow ui --backend-store-uri \"$tracking_uri\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access MLflow portal\n",
        "\n",
        "The port opened by MLflow needs to be access locally. To work around this, open a tunnel using SSH:\n",
        "\n",
        "`ssh azureuser@[your notebook IP] -L 5000:localhost:5000`\n",
        "\n",
        "This is not the recommended approach for deploying MLflow in production; however, it is a simple, secure option for a demo environment.\n",
        "\n",
        "Once connected, you can navigate to `localhost:5000` in your browser."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "environment": {
      "name": "common-cu101.m58",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cu101:m58"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
