{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Flight Delay Demo - Security & Enterprise Readiness"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "import logging\r\n",
        "logging.basicConfig(level = logging.ERROR)"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1625754148444
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup working directory\r\n",
        "\r\n",
        "The cell below creates our working directory. This will hold our generated scripts."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import os\r\n",
        "\r\n",
        "project_folder = './scripts'\r\n",
        "\r\n",
        "# Working directory\r\n",
        "if not os.path.exists(project_folder):\r\n",
        "    os.makedirs(project_folder)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754149602
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting started\n",
        "\n",
        "Import and verify the Azure ML SDK version."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import azureml.core\r\n",
        "\r\n",
        "azureml.core.VERSION"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754150836
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to workspace\r\n",
        "\r\n",
        "In the next cell, we create a new Workspace config object using the `<subscription_id>`, `<resource_group_name>`, and `<workspace_name>`. This will fetch the matching Workspace and prompt you for authentication. Please click on the link and input the provided details.\r\n",
        "\r\n",
        "For more information on **Workspace**, please visit: [Microsoft Workspace Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py)\r\n",
        "\r\n",
        "`<subscription_id>` = You can get this ID from the landing page of your Resource Group.\r\n",
        "\r\n",
        "`<resource_group_name>` = This is the name of your Resource Group.\r\n",
        "\r\n",
        "`<workspace_name>` = This is the name of your Workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.workspace import Workspace\r\n",
        "\r\n",
        "try:    \r\n",
        "    # Get instance of the Workspace and write it to config file\r\n",
        "    ws = Workspace(\r\n",
        "        subscription_id = '<subscription_id>', \r\n",
        "        resource_group = '<resource_group>', \r\n",
        "        workspace_name = '<workspace_name>')\r\n",
        "\r\n",
        "    # Writes workspace config file\r\n",
        "    ws.write_config()\r\n",
        "    \r\n",
        "    print('Library configuration succeeded')\r\n",
        "except Exception as e:\r\n",
        "    print(e)\r\n",
        "    print('Workspace not found')"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754153557
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data from Azure Dataset Registry\r\n",
        "\r\n",
        "First step is to get our data using the Dataset module, the function `Dataset.get_by_name()` returns a registered Dataset from a given `workspace` and its registration `name`.\r\n",
        "\r\n",
        "`workspace` = The existing AzureML workspace in which the Dataset was registered..\r\n",
        "\r\n",
        "`name` = The registration name.\r\n",
        "\r\n",
        "`dataframe.take() ` = Function returns the elements in the given positional indices along an axis. \r\n",
        "\r\n",
        "For more information on **Dataset**, please visit: [Microsoft Dataset Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py#get-by-name-workspace--name--version--latest--)\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Dataset\r\n",
        "\r\n",
        "tabular = Dataset.get_by_name(ws, 'flight_dataset_2008_with_weather')\r\n",
        "\r\n",
        "data = tabular.to_pandas_dataframe()\r\n",
        "tabular.take(3).to_pandas_dataframe()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754162425
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch existing AML Compute Cluster\r\n",
        "\r\n",
        "**Note:** This cluster was deployed by the setup guide. The cluster sits under a private VNet."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.compute import ComputeTarget\r\n",
        "\r\n",
        "### Create AML CPU Compute Cluster\r\n",
        "compute_target = ComputeTarget(workspace=ws, name='cpu-cluster')\r\n",
        "print('Found existing compute target.')"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754162884
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate an Automated ML Config\r\n",
        "Before the execution of an Automated ML run, the `AutoMLConfig` should be setup. `AutoMLConfig` is a configuration object that contains and persists the parameters for configuring the experiment run parameters. This configuration is a key element in the execution of the run since it defines things such as the number of iterations and primary metric to optimize on. In the example below the run will be setup to execute a regression task with 25 iterations and using `accuracy` as primary metric.\r\n",
        "\r\n",
        "For more information on **AutoMLConfig**, please visit: [Microsoft AutoMLConfig Documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlconfig?view=azure-ml-py)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "\r\n",
        "training_data, validation_data = tabular.random_split(percentage=0.9, seed=1)\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task = 'classification',\r\n",
        "                             iterations = 3,\r\n",
        "                             iteration_timeout_minutes = 30, \r\n",
        "                             max_cores_per_iteration = 10,\r\n",
        "                             primary_metric = 'accuracy',\r\n",
        "                             debug_log = 'automl.log',\r\n",
        "                             training_data = training_data,\r\n",
        "                             validation_data = validation_data,\r\n",
        "                             label_column_name = \"ArrDelay15\",\r\n",
        "                             compute_target = compute_target,\r\n",
        "                             path = project_folder,\r\n",
        "                             model_explainability = True,\r\n",
        "                             experiment_exit_score = 0.8,\r\n",
        "                             enable_early_stopping = True,\r\n",
        "                             enable_onnx_compatible_models=True)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754163489
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run our Experiment on AML Compute\r\n",
        "\r\n",
        "The Experiment constructor allows to create an experiment instance. The constructor takes in the current workspace, which is fetched by calling `Workspace.from_config()` and an experiment name. \r\n",
        "\r\n",
        "The `experiment.submit()` function is called to send the experiment for execution. The only parameter received by this function is the `AutoMLConfig` object instantiated previously in this module.\r\n",
        "\r\n",
        "For more information on **Experiment**, please visit: [Microsoft Experiment Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.experiment import Experiment\r\n",
        "\r\n",
        "# Get an instance of the Workspace from the config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "ws.update(image_build_compute = 'cpu-cluster')\r\n",
        "\r\n",
        "# Create Experiment\r\n",
        "experiment = Experiment(ws, 'flight-delay-exp')\r\n",
        "\r\n",
        "remote_run = experiment.submit(automl_config, show_output=False)\r\n",
        "remote_run"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754170774
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Automated ML Run Details\r\n",
        "The creation of an object of type `AutoMLRun` will enable us to observe the experiment progress and results. The object is created by calling the constructor `AutoMLRun()`. It takes as arguments the experiment and the identifier of the run to fetch. After the object has been instantiated, the `RunDetails()` function will retrieve the progress, metrics, and tasks for the specified run. They will be displayed by calling the function `show()` over the mentioned object.\r\n",
        "\r\n",
        "For more information on **AutoMLRun**, please visit: [Microsoft AutoMLRun Documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.run.automlrun?view=azure-ml-py)\r\n",
        "\r\n",
        "For more information on **RunDetails**, please visit: [Microsoft RunDetails Documentation](https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets.rundetails?view=azure-ml-py)\r\n",
        "\r\n",
        "\r\n",
        "**Note:** Please wait for the execution of the cell to finish before moving forward. (Status should be **Completed**)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.train.automl.run import AutoMLRun \r\n",
        "from azureml.widgets import RunDetails\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "\r\n",
        "experiment = Experiment(ws, 'flight-delay-exp')\r\n",
        "remote_run = AutoMLRun(experiment=experiment, run_id=remote_run.id)\r\n",
        "\r\n",
        "RunDetails(remote_run).show()"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625754172655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show best run\r\n",
        "\r\n",
        "Select the best model from your iterations. The `get_output` function returns the best run and the fitted model for the last fit invocation. By using the overloads on get_output, you can retrieve the best run and fitted model for any logged metric or a particular iteration."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "remote_run.wait_for_completion()\r\n",
        "best_run, fitted_model = remote_run.get_output()\r\n",
        "print(best_run)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625755067197
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register Model\r\n",
        "\r\n",
        "Next, register the model obtained from the best run. In order to register the model, the function `register_model()` should be called. This will take care of registering the model obtained from the best run."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# register the model for deployment\r\n",
        "model = best_run.register_model(model_name='flight_delay_weather', \r\n",
        "                                model_path='outputs/model.pkl',\r\n",
        "                                datasets=[(Dataset.Scenario.TRAINING, tabular)])"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625755069941
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "from azureml.core.model import Model\r\n",
        "model = Model(ws, 'flight_delay_weather')"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625755070794
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create/connect to the Kubernetes compute cluster\r\n",
        "\r\n",
        "The `AksCompute Class` manages an Azure Kubernetes Service compute target in Azure Machine Learning.\r\n",
        "\r\n",
        "The `ComputeTarget Class` is an abstract parent class for all compute targets managed by Azure Machine Learning. A compute target is a designated compute resource/environment where you run your training script or host your service deployment. \r\n",
        "\r\n",
        "The `ComputeTargetException` is an exception related to failures when creating, interacting with, or configuring a compute target. This exception is commonly raised for failures attaching a compute target, missing headers, and unsupported configuration values.\r\n",
        "\r\n",
        "For more information on **AksCompute Class**, please visit: [Microsoft Machine Learning - AksCompute Class Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.aks.akscompute?view=azure-ml-py)\r\n",
        "\r\n",
        "For more information on **ComputeTarget Class**, please visit: [Microsoft Machine Learning - ComputeTarget Class Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computetarget?view=azure-ml-py)\r\n",
        "\r\n",
        "For more information on **ComputeTargetException Class**, please visit: [Microsoft Machine Learning - ComputeTargetException Class Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.exceptions.computetargetexception?view=azure-ml-py)\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.compute import ComputeTarget, AksCompute\r\n",
        "from azureml.exceptions import ComputeTargetException\r\n",
        "\r\n",
        "try:\r\n",
        "    aks_target = AksCompute(ws, 'secure-aks')\r\n",
        "except ComputeTargetException:\r\n",
        "    # Create the compute configuration and set virtual network information\r\n",
        "    config = AksCompute.provisioning_configuration(location=\"<region>\")\r\n",
        "    config.vnet_resourcegroup_name = \"<resource-group-name>\"\r\n",
        "    config.vnet_name = \"<vnet-name>\"\r\n",
        "    config.subnet_name = \"<subnet-name>\"\r\n",
        "    config.service_cidr = \"10.0.0.0/16\"\r\n",
        "    config.dns_service_ip = \"10.0.0.10\"\r\n",
        "    config.docker_bridge_cidr = \"172.17.0.1/16\"\r\n",
        "    config.vm_size = \"Standard_DS2_v2\"\r\n",
        "\r\n",
        "    # Create the compute target\r\n",
        "    aks_target = ComputeTarget.create(workspace=ws,\r\n",
        "                                    name=\"secure-aks\",\r\n",
        "                                    provisioning_configuration=config)\r\n",
        "    aks_target.wait_for_completion(True)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625758677043
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update AKS to enable the Internal Load Balancer\n",
        "\n",
        "The internal load balancer enables services to be published to the virtual network."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core.compute.aks import AksUpdateConfiguration\r\n",
        "\r\n",
        "# Change to the name of the subnet that contains AKS\r\n",
        "subnet_name = \"<subnet-name>\"\r\n",
        "# Update AKS configuration to use an internal load balancer\r\n",
        "update_config = AksUpdateConfiguration(None, \"InternalLoadBalancer\", subnet_name)\r\n",
        "aks_target.update(update_config)\r\n",
        "# Wait for the operation to complete\r\n",
        "aks_target.wait_for_completion(show_output = True)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625758798838
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Scoring File\r\n",
        "\r\n",
        "Creating the scoring file is next step before deploying the service. This file is responsible for the actual generation of predictions using the model. The values or scores generated can represent predictions of future values, but they might also represent a likely category or outcome.\r\n",
        "\r\n",
        "The first thing to do in the scoring file is to fetch the model. This is done by calling `Model.get_model_path()` and passing the model name as a parameter.\r\n",
        "\r\n",
        "After the model has been loaded, the function `model.predict()` function should be called to start the scoring process.\r\n",
        "\r\n",
        "For more information on **Machine Learning - Score**, please visit: [Microsoft Machine Learning - Score Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/machine-learning-score)\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile score.py\r\n",
        "import pickle\r\n",
        "import json\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import azureml.automl.core\r\n",
        "from azureml.core.model import Model\r\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
        "from sklearn.externals import joblib\r\n",
        " \r\n",
        "input_sample = np.array([[3,30,7,820,930,'MQ',70,'DFW','LIT',304,32.89595056,-97.0372,'TX',34.72939611,-92.22424556,'AR',44236.8,44236.8,0.0,11.0,409.6,208.0,0.0,0.0,28.5,16.0,15.0,8.5,1720.0,1120.0]])\r\n",
        "output_sample = np.array([1])\r\n",
        " \r\n",
        "def init():\r\n",
        "    global model, inputs_dc, prediction_dc\r\n",
        "    print (\"model initialized\" + time.strftime(\"%H:%M:%S\"))\r\n",
        "    \r\n",
        "    # this name is model.id of model that we want to deploy\r\n",
        "    model_path = Model.get_model_path(model_name = 'flight_delay_weather')\r\n",
        "    \r\n",
        "    # deserialize the model file back into a sklearn model\r\n",
        "    model = joblib.load(model_path)\r\n",
        "    \r\n",
        "@input_schema('data', NumpyParameterType(input_sample))\r\n",
        "@output_schema(NumpyParameterType(output_sample))\r\n",
        "def run(data):\r\n",
        "    try:\r\n",
        "        df = pd.DataFrame(data, columns=['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime', 'UniqueCarrier', 'CRSElapsedTime', 'Origin', 'Dest', 'Distance', 'Origin_Lat', 'Origin_Lon', 'Origin_State', 'Dest_Lat', 'Dest_Lon', 'Dest_State', 'Origin_dayl', 'Dest_dayl', 'Origin_prcp', 'Dest_prcp', 'Origin_srad', 'Dest_srad', 'Origin_swe', 'Dest_swe', 'Origin_tmax', 'Dest_tmax', 'Origin_tmin', 'Dest_tmin', 'Origin_vp', 'Dest_vp']) \r\n",
        "        result = model.predict(df)\r\n",
        "    except Exception as e:\r\n",
        "        result = str(e)\r\n",
        "        print(result)\r\n",
        "        return {\"error\": result}\r\n",
        "    return {\"result\":result.tolist()}"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Environment Definition File\n",
        "\n",
        "The dependencies file allows us to define the libraries to be included in the inferencing environment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile score-new.yml\r\n",
        "name: project_environment\r\n",
        "dependencies:\r\n",
        "  # The python interpreter version.\r\n",
        "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
        "- python=3.6.2\r\n",
        "\r\n",
        "- pip:\r\n",
        "  - azureml-sdk[notebooks,automl]\r\n",
        "  - azureml-defaults\r\n",
        "  - inference-schema\r\n",
        "  - azureml-monitoring\r\n",
        "  - joblib\r\n",
        "- numpy\r\n",
        "- scikit-learn\r\n",
        "channels:\r\n",
        "- anaconda\r\n",
        "- conda-forge"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model to AKS\r\n",
        "\r\n",
        "The first step is to define the dependencies that are needed for the service to run and they are defined by calling `CondaDependencies.create()`. This create function will receive as parameters the pip and conda packages to install on the remote machine. Secondly, the output of this function is persisted into a `.yml` file that will be leveraged later on the process.\r\n",
        "\r\n",
        "Now that the AKS cluster has been deployed and our CondaDependencies have been declared, it’s time to create an `InferenceConfig` object by calling its constructor and passing the runtime type, the path to the `entry_script` (score.py), and the `conda_file` (the previously created file that holds the environment dependencies).\r\n",
        "\r\n",
        "Next, define the configuration of the web service to deploy. This is done by calling `AksWebservice.deploy_configuration()` and passing along the number of `cpu_cores` and `memory_gb` that the service needs.\r\n",
        "\r\n",
        "Finally, in order to deploy the model and service to the created AKS cluster, the function `Model.deploy()` should be called, passing along the workspace object, a list of models to deploy, the defined inference configuration, deployment configuration, and the AKS object created in the step above.\r\n",
        "\r\n",
        "For more information on **CondaDependencies**, please visit: [Microsoft CondaDependencies Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py)\r\n",
        "\r\n",
        "For more information on **InferenceConfig**, please visit: [Microsoft InferenceConfig Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py)\r\n",
        "\r\n",
        "For more information on **AksWebService**, please visit: [Microsoft AksWebService Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.akswebservice?view=azure-ml-py)\r\n",
        "\r\n",
        "For more information on **Model**, please visit: [Microsoft Model Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py)\r\n",
        "\r\n",
        "\r\n",
        "**Note:** Please wait for the execution of the cell to finish before moving forward."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.exceptions import WebserviceException\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AksWebservice\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load workspace from an existing config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "# Update the workspace to use an existing compute cluster\r\n",
        "ws.update(image_build_compute = 'cpu-cluster')\r\n",
        "\r\n",
        "inference_config = InferenceConfig(runtime= \"python\",\r\n",
        "                                    entry_script=\"score.py\",\r\n",
        "                                    conda_file=\"score-new.yml\")\r\n",
        "\r\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, \r\n",
        "                                                        memory_gb = 1,\r\n",
        "                                                        collect_model_data=True, \r\n",
        "                                                        enable_app_insights=True)\r\n",
        "\r\n",
        "try:\r\n",
        "    service = AksWebservice(ws, 'flight-delay-secure')\r\n",
        "    print(service.state)\r\n",
        "except WebserviceException:\r\n",
        "    service = Model.deploy(ws, \r\n",
        "                            'flight-delay-secure', \r\n",
        "                            [model], \r\n",
        "                            inference_config, \r\n",
        "                            deployment_config, \r\n",
        "                            aks_target)\r\n",
        "\r\n",
        "    service.wait_for_deployment(show_output = True)\r\n",
        "    print(service.state)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625763618289
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the deployed webservice\r\n",
        "\r\n",
        "Now with test data, we can get it into a suitable format to consume the web service. First an instance of the web service should be obtained by calling the constructor `Webservice()` with the Workspace object and the service name as parameters. Sanitizing of the data is then performed in order to avoid sending unexpected columns to the web service. Finally, call the service via POST using the `requests` module. `requests.post()` will call the deployed web service. It takes for parameters the service URL, the test data, and a headers dictionary that contains the authentication token.\r\n",
        "\r\n",
        "For more information on **Webservice**, please visit: [Microsoft Webservice Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice?view=azure-ml-py)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "import json\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from azureml.core.webservice import Webservice\r\n",
        "\r\n",
        "aks_service = Webservice(ws, 'flight-delay-secure')\r\n",
        "aks_service.update(enable_app_insights=True)\r\n",
        "\r\n",
        "# prepare the test data\r\n",
        "val = validation_data.to_pandas_dataframe()\r\n",
        "val = val.drop(columns=['ArrDelay15'])\r\n",
        "sample = val.sample(n=10, random_state=4).values.tolist()\r\n",
        "\r\n",
        "headers = {'Content-Type':'application/json'}\r\n",
        "\r\n",
        "if aks_service.auth_enabled:\r\n",
        "    headers['Authorization'] = 'Bearer '+ aks_service.get_keys()[0]\r\n",
        "\r\n",
        "output_df = []\r\n",
        "for x in sample:    \r\n",
        "    test_sample = json.dumps({'data': [x]})\r\n",
        "    response = requests.post(aks_service.scoring_uri, data=test_sample, headers=headers)\r\n",
        "    prediction = [response.json()['result'][0]]\r\n",
        "    prediction.extend(x)\r\n",
        "    output_df.append(prediction)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625763865377
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the IP of the scoring webservice\n",
        "\n",
        "The IP address of the service shows it is connected to the virtual network."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "service.scoring_uri"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625763924509
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Present scoring service predictions\r\n",
        "\r\n",
        "Let's format our service responses and present them in a suitable way to our end users."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def highlight_delays(val):\r\n",
        "    return 'background-color: yellow' if val == True else ''\r\n",
        "\r\n",
        "predictions = pd.DataFrame(output_df, columns =['Prediction', 'Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'CRSArrTime', 'UniqueCarrier', 'CRSElapsedTime', 'Origin', 'Dest', 'Distance', 'Origin_Lat', 'Origin_Lon', 'Origin_State', 'Dest_Lat', 'Dest_Lon', 'Dest_State', 'Origin_dayl', 'Dest_dayl', 'Origin_prcp', 'Dest_prcp', 'Origin_srad', 'Dest_srad', 'Origin_swe', 'Dest_swe', 'Origin_tmax', 'Dest_tmax', 'Origin_tmin', 'Dest_tmin', 'Origin_vp', 'Dest_vp'])\r\n",
        "predictions = predictions.style.applymap(highlight_delays, subset=['Prediction'])\r\n",
        "predictions"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625763885800
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}