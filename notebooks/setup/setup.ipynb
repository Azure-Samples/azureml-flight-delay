{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Prepare the Workspace\n",
        "\n",
        "Welcome to your AML workspace.\n",
        "Use the Python 3.8 - AzureML kernel\n",
        "And be sure to authenticate to Azure if this is the first time you're logging in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Upload files to datastore\n",
        "\n",
        "First we'll load the datasets that we'll use for the first two demos into blob storage from the cloned repo in your user storage file share."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628529463802
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "datastore = Datastore.get(ws, 'workspaceblobstore')\n",
        "ds = Dataset.File.upload_directory(src_dir='../../azureStorageFiles',\n",
        "    target=DataPath(datastore,'/flightdelay'),\n",
        "    overwrite=True,\n",
        "    show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Load files to tabular Dataset\n",
        "\n",
        "Several tabular datasets are used to support different parts of the demos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628530036639
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "airports = Dataset.Tabular.from_delimited_files(path=[(datastore, '/flightdelay/airports.csv')])\n",
        "carriersdataset = Dataset.Tabular.from_delimited_files(path=[(datastore, '/flightdelay/carriersdataset.csv')])\n",
        "flight_dataset_2008 = Dataset.Tabular.from_delimited_files(path=[(datastore, '/flightdelay/flight_dataset_2008.csv')])\n",
        "plane_data = Dataset.Tabular.from_delimited_files(path=[(datastore, '/flightdelay/plane-data.csv')])\n",
        "flightdelayweather_ds_clean = Dataset.Tabular.from_delimited_files(path=[(datastore, '/flightdelay/flightdelayweather_ds_clean.csv')])\n",
        "flight_dataset_2008_with_weather = Dataset.Tabular.from_delimited_files(path=[(datastore, '/flightdelay/flight_dataset_2008_with_weather.csv')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Register Datasets to Workspace\n",
        "\n",
        "By registering the datasets, we can link experiment runs to them throughout the demo series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628530430623
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "airports_ds = airports.register(workspace=ws, name='/flightdelay/airports_ds', create_new_version=True)\n",
        "carriers_ds = carriersdataset.register(workspace=ws, name='/flightdelay/carriers_ds', create_new_version=True)\n",
        "flightdelay_ds_raw = flight_dataset_2008.register(workspace=ws, name='/flightdelay/flightdelay_ds_raw', create_new_version=True)\n",
        "flightdelay_ds = flight_dataset_2008_with_weather.register(workspace=ws, name='/flightdelay/flightdelay_ds', create_new_version=True)\n",
        "flight_dataset_2008_with_weather = flight_dataset_2008_with_weather.register(workspace=ws, name='/flightdelay/flight_dataset_2008_with_weather', create_new_version=True)\n",
        "flightdelayweather_ds_clean = flightdelayweather_ds_clean.register(workspace=ws, name='/flightdelay/flightdelayweather_ds_clean', create_new_version=True)\n",
        "\n",
        "# flightdelayweather_ds = flight_dataset_2008_with_weather.register(workspace=ws, name='/flightdelay/flightdelayweather_ds', create_new_version=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create AML Cluster\n",
        "\n",
        "A CPU cluster is used for remote training scenarios in later demos. The compute cluster is 4 nodes, but autoscales to 0 by default. You can move on after starting cluster create."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628532481602
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "### Create AML CPU Compute Cluster\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name='cpu-cluster')\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_v2',\n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, 'cpucluster', compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "dea828ca9184007e6554a9149e352315e09f977962d3ceb2b00c7e155a3b8fb0"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
