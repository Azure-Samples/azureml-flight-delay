{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Connect to Workspace\n",
        "\n",
        "Connect to your AML workspace.\n",
        "Use the Python 3.8 - AzureML kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1628528449504
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "try:    \n",
        "    # Get instance of the Workspace and write it to config file\n",
        "    ws = Workspace(\n",
        "        subscription_id = '<subscription_id>', \n",
        "        resource_group = '<resource_group>', \n",
        "        workspace_name = '<workspace_name>')\n",
        "\n",
        "    # Writes workspace config file\n",
        "    ws.write_config()\n",
        "    \n",
        "    print('Library configuration succeeded')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print('Workspace not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Upload files to datastore\n",
        "\n",
        "Load the datasets into blob storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628529463802
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "datastore = Datastore.get(ws, 'workspaceblobstore')\n",
        "ds = Dataset.File.upload_directory(src_dir='../../azureStorageFiles',\n",
        "    target=DataPath(datastore,'/flightdelay'),\n",
        "    overwrite=True,\n",
        "    show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Load files to tabular Dataset\n",
        "\n",
        "A range of datasets are used to support different parts of the demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628530036639
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "airports = Dataset.Tabular.from_delimited_files(path=[(datastore, 'airports.csv')])\n",
        "carriersdataset = Dataset.Tabular.from_delimited_files(path=[(datastore, 'carriersdataset.csv')])\n",
        "flight_dataset_2008 = Dataset.Tabular.from_delimited_files(path=[(datastore, 'flight_dataset_2008.csv')])\n",
        "plane_data = Dataset.Tabular.from_delimited_files(path=[(datastore, 'plane-data.csv')])\n",
        "flightdelayweather_ds_clean = Dataset.Tabular.from_delimited_files(path=[(datastore, 'flightdelayweather_ds_clean.csv')])\n",
        "flight_dataset_2008_with_weather = Dataset.Tabular.from_delimited_files(path=[(datastore, 'flight_dataset_2008_with_weather.csv')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Register Datasets to Workspace\n",
        "\n",
        "By registering the datasets, we can link experiment runs to them throughout the demo series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628530430623
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "airports_ds = airports.register(workspace=ws, name='airports_ds', create_new_version=True)\n",
        "flightdelayweather_ds = flight_dataset_2008_with_weather.register(workspace=ws, name='flightdelayweather_ds', create_new_version=True)\n",
        "carriers_ds = carriersdataset.register(workspace=ws, name='carriers_ds', create_new_version=True)\n",
        "flightdelay_ds_raw = flight_dataset_2008.register(workspace=ws, name='flightdelay_ds_raw', create_new_version=True)\n",
        "flightdelay_ds = flight_dataset_2008_with_weather.register(workspace=ws, name='flightdelay_ds', create_new_version=True)\n",
        "flight_dataset_2008_with_weather = flight_dataset_2008_with_weather.register(workspace=ws, name='flight_dataset_2008_with_weather', create_new_version=True)\n",
        "flightdelayweather_ds_clean = flightdelayweather_ds_clean.register(workspace=ws, name='flightdelayweather_ds_clean', create_new_version=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create AML Cluster\n",
        "\n",
        "A CPU cluster is used for remote training scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628532481602
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "### Create AML CPU Compute Cluster\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name='cpucluster')\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_v2',\n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, 'cpucluster', compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
