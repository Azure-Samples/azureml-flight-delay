{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Responsible ML - Differential Privacy with SmartNoise \n",
        "\n",
        "## Install prerequisites\n",
        "\n",
        "Before running the notebook, make sure the correct versions of these libraries are installed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install opendp-smartnoise"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install z3-solver"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install pandas --upgrade"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!conda install protobuf -y"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup working directory\n",
        "\n",
        "The cell below creates our working directory. This will hold our generated scripts."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "project_folder = './scripts'\r\n",
        "\r\n",
        "if not os.path.exists(project_folder):\r\n",
        "    os.makedirs(project_folder)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update Workspace details in script below\n",
        "\n",
        "In the next cell, we update a Workspace config object using the `<subscription_id>`, `<resource_group_name>`, and `<workspace_name>`. This will fetch the matching Workspace and prompt you for authentication. Please click on the link and input the provided details.\n",
        "\n",
        "For more information on **Workspace**, please visit: [Microsoft Workspace Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py)\n",
        "\n",
        "`<subscription_id>` = You can get this ID from the landing page of your Resource Group.\n",
        "\n",
        "`<resource_group_name>` = This is the name of your Resource Group.\n",
        "\n",
        "`<workspace_name>` = This is the name of your Workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%writefile $project_folder/utils.py\n",
        "import pandas as pd\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "import z3\n",
        "import reconstruction_module as rec\n",
        "import numpy as np\n",
        "\n",
        "def get_data():\n",
        "    df = pd.read_parquet('creditdataset.parquet')\n",
        "    return df\n",
        "\n",
        "def fetch_data():\n",
        "    df = pd.read_parquet('creditdataset.parquet')\n",
        "    df = df.sample(n=500)\n",
        "    df = df.select_dtypes(include='int')\n",
        "    df = df.iloc[:,2:12]\n",
        "    return df\n",
        "\n",
        "def register_privatized_dataset(synth_df):\n",
        "    ## \n",
        "    ## Update workspace details\n",
        "    ##\n",
        "    ws = Workspace(\n",
        "        subscription_id = '<subscription_id>', \n",
        "        resource_group = '<resource_group>', \n",
        "        workspace_name = '<workspace_name>')\n",
        "    ws.write_config()\n",
        "    datastore = ws.get_default_datastore()\n",
        "    synth_df.to_csv('privatized_ds.csv',index=False)\n",
        "    datastore.upload_files(files=['privatized_ds.csv'], overwrite=True)\n",
        "    datastore_path = [DataPath(datastore, 'privatized_ds.csv')]\n",
        "    tabular = Dataset.Tabular.from_delimited_files(path=datastore_path)\n",
        "    tabular = tabular.register(workspace=ws, \n",
        "                           name='privatized_ds',\n",
        "                           description='Privatized training data',\n",
        "                           create_new_version=True)\n",
        "    tabular = Dataset.get_by_name(ws, 'privatized_ds')\n",
        "    print(tabular.version)\n",
        "\n",
        "def percentage(part, whole):\n",
        "    return 100 * float(part)/float(whole)\n",
        "\n",
        "def endcode_solver_data():\n",
        "    rawDataset = pd.read_parquet('creditdataset.parquet')\n",
        "    rawDataset.to_csv('creditdataset.csv', index=False)\n",
        "\n",
        "    # load data \n",
        "    orig_data, data = rec.load_data()\n",
        "    non_income_data = data.drop('INCOME', axis = 1)\n",
        "\n",
        "    # get plausible variable combinations and subset of length 5 plausible combinations \n",
        "    plausible_variable_combinations = rec.get_plausible_variable_combinations(non_income_data)\n",
        "    plausible_variable_combinations_names = ['__'.join(combination) for combination in plausible_variable_combinations]\n",
        "\n",
        "    five_way_interactions = [combination for combination in plausible_variable_combinations if len(combination) == 5]\n",
        "    five_way_interactions_names = ['__'.join(combination) for combination in five_way_interactions]\n",
        "\n",
        "    # get dictionaries of private and non-private releases (up to 5-way interactions)\n",
        "    count_dict, priv_count_dict, mean_income_dict, priv_mean_income_dict, median_income_dict, priv_median_income_dict, min_income_dict, priv_min_income_dict, max_income_dict, priv_max_income_dict = rec.create_dicts(data, non_income_data, plausible_variable_combinations)\n",
        "\n",
        "    # get string representations of each element associated with each tuple representing the 5-way interactions\n",
        "    elem_dict, priv_elem_dict = rec.create_elem_dicts(count_dict, priv_count_dict, five_way_interactions, five_way_interactions_names)\n",
        "    \n",
        "    # set applications\n",
        "    applications, priv_applications = rec.get_applications(five_way_interactions, five_way_interactions_names,\n",
        "                                                    plausible_variable_combinations, plausible_variable_combinations_names,\n",
        "                                                    count_dict, priv_count_dict, \n",
        "                                                    mean_income_dict, priv_mean_income_dict,\n",
        "                                                    median_income_dict, priv_median_income_dict,\n",
        "                                                    min_income_dict, priv_min_income_dict,\n",
        "                                                    max_income_dict, priv_max_income_dict,\n",
        "                                                    elem_dict, priv_elem_dict, lowest_allowable_count = 1,\n",
        "                                                    use_medians = True, use_mins = False, use_maxes = False)\n",
        "    # remove duplicate applications\n",
        "    applications = list(set(applications))\n",
        "    priv_applications = list(set(priv_applications))\n",
        "    \n",
        "    # set applications\n",
        "    applications_3, priv_applications_3 = rec.get_applications(five_way_interactions, five_way_interactions_names,\n",
        "                                                plausible_variable_combinations, plausible_variable_combinations_names,\n",
        "                                                count_dict, priv_count_dict, \n",
        "                                                mean_income_dict, priv_mean_income_dict,\n",
        "                                                median_income_dict, priv_median_income_dict,\n",
        "                                                min_income_dict, priv_min_income_dict,\n",
        "                                                max_income_dict, priv_max_income_dict,\n",
        "                                                elem_dict, priv_elem_dict, lowest_allowable_count = 10,\n",
        "                                                use_medians = True, use_mins = False, use_maxes = False)\n",
        "    \n",
        "    return orig_data, applications_3, priv_applications_3, count_dict, elem_dict"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ---- Restart Kernel ----"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration\n",
        "\n",
        "Let's take a look at the different trends and distribuitions we are able to find in the open dataset.\n",
        "\n",
        "### Distribution of income across different Age Groups\n",
        "\n",
        "Plot distribuition of income accross different age groups."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from scripts.utils import *\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = get_data()\n",
        "df = df.sort_values(by=['AGE_GROUP'])\n",
        "sns.set(style=\"ticks\")\n",
        "f, ax = plt.subplots(figsize=(14.5, 6.5))\n",
        "ax.set_xscale(\"log\")\n",
        "\n",
        "sns.boxplot(x=\"INCOME\", y=\"AGE_GROUP\", data=df,\n",
        "            whis=[0, 100], palette=\"vlag\")\n",
        "\n",
        "\n",
        "sns.swarmplot(x=\"INCOME\", y=\"AGE_GROUP\", data=df,\n",
        "              size=2, color=\".3\", linewidth=0)\n",
        "\n",
        "ax.xaxis.grid(True)\n",
        "ax.set(ylabel=\"\")\n",
        "sns.despine(trim=True, left=True)\n",
        "plt.title('Distribution of income across different Age Groups')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Suggested Approvals by Income and Age Group\n",
        "\n",
        "Letâ€™s analyze how our dataset approval suggestions are distributed across the different incomes and age groups."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "f, ax = plt.subplots(figsize=(14.5, 6.5))\n",
        "# Draw a nested violinplot and split the violins for easier comparison\n",
        "sns.violinplot(x=\"AGE_GROUP\", y=\"INCOME\", hue=\"SHOULD_APPROVE\",\n",
        "               split=True, inner=\"quart\",\n",
        "               data=df, ax=ax)\n",
        "sns.despine(left=True)\n",
        "plt.title('Suggested Approvals by Income and Age Group')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Employment Length Scatter Plot\n",
        "\n",
        "We are also able to take a look at the different employment lengths that we have across our current dataset and group it by city and income ranges."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "f, ax = plt.subplots(figsize=(14.5, 6.5))\n",
        "sns.despine(f, left=True, bottom=True)\n",
        "sns.scatterplot(x=\"AGE\", y=\"EMPLOYMENT_LENGTH\",\n",
        "                hue=\"CITY\", size=\"INCOME\",\n",
        "                palette=\"ch:r=-.2,d=.3_r\",\n",
        "                sizes=(10, 400), linewidth=0,\n",
        "                data=df, ax=ax)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.title('Employment Length Scatter Plot')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requests Heatmap\n",
        "\n",
        "Analyze how many requests are contained in our dataset and to which city and month they belong to."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import datetime\n",
        "\n",
        "df['APPLICATION_DATE'] =  pd.to_datetime(df['APPLICATION_DATE'], format='%m/%d/%Y')\n",
        "heatmap = df[['APPLICANT_ID','CITY','APPLICATION_DATE']]\n",
        "heatmap['MONTH'] = df['APPLICATION_DATE'].dt.strftime(\"%B\")\n",
        "heatmap = heatmap.drop(columns=['APPLICATION_DATE'])\n",
        "heatmap = pd.DataFrame({'APPLICANTS' : heatmap.groupby(['MONTH','CITY']).size()}).reset_index()\n",
        "heatmap = heatmap.pivot(\"MONTH\", \"CITY\", \"APPLICANTS\")\n",
        "heatmap = heatmap.dropna()\n",
        "heatmap\n",
        "f, ax = plt.subplots(figsize=(14.5, 6.5))\n",
        "sns.heatmap(heatmap, annot=True, linewidths=.5, ax=ax)\n",
        "plt.title('Requests Heatmap')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Employment Length by Age\n",
        "\n",
        "The dataset also contains data that will allow us to see the different employment lengths that where recorded at the time that the application was submitted."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "sns.jointplot(df['AGE'], df['EMPLOYMENT_LENGTH'], kind=\"hex\", color=\"#4CB391\", height=8.5)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differential Privacy\n",
        "\n",
        "Differential Privacy is a technology that enables researchers and analysts to extract useful answers from\n",
        "databases containing personal information and, at the same time, offers strong individual privacy\n",
        "protections."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Dataset Reconstruction Attack\n",
        "\n",
        "The following cells will walk us through a dataset reconstruction attack in which we will attempt to reconstruct the non-private dataset based on its statistical features.\n",
        "\n",
        "### Income Analysis\n",
        "\n",
        "Income distribuition for individuals with a `DEGREE`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import z3\n",
        "import reconstruction_module as rec\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "\n",
        "orig_data, applications_3, priv_applications_3, count_dict, elem_dict = endcode_solver_data()\n",
        "\n",
        "# define sample of interest\n",
        "sample_of_interest = orig_data.loc[orig_data['DEGREE'] == 1]\n",
        "\n",
        "\n",
        "# define bin edges\n",
        "hist_edges = list(range(0, 110000, 10000))\n",
        "\n",
        "\n",
        "# get non-private histogram values\n",
        "binned_income = pd.cut(sample_of_interest['INCOME'], hist_edges, right = False)\n",
        "binned_income = binned_income.cat.add_categories('>= 100,000')\n",
        "binned_income.fillna('>= 100,000', inplace = True)\n",
        "non_priv_hist = list(binned_income.value_counts().sort_index())\n",
        "\n",
        "df = pd.DataFrame({'income': [str(cat) for cat in list(binned_income.cat.categories)] * 1,\n",
        "                   'count': non_priv_hist,\n",
        "                   'version': ['non-private'] * len(non_priv_hist) })\n",
        "\n",
        "sns.barplot(x = 'income', y = 'count', hue = 'version', data = df)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title('Distribution of income for individuals with a degree')\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstruction Attack\n",
        "\n",
        "Imagine that the attacker has access to the following information outside of the statistical releases:\n",
        "\n",
        "1. There is at least one person in the data with `DEGREE == 1`, `EMPLOYED == 2`, `agebinned == [45, 50)`, `SEX == 0`, and `MARRIED == 1` with an income of 95,000.\n",
        "1. There is only one person in the data with `DEGREE == 1`, `EMPLOYED == 2`, `agebinned == [45, 50)`, `SEX == 1`, and `MARRIED == 1` and they have an income of 31,000."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# remove duplicate applications\n",
        "applications_3 = list(set(applications_3))\n",
        "priv_applications_3 = list(set(priv_applications_3))\n",
        "\n",
        "# initialize solvers\n",
        "solver_3, solver_list_3 = rec.applications_to_solver(applications_3)\n",
        "priv_solver_3, priv_solver_list_3 = rec.applications_to_solver(priv_applications_3) \n",
        "\n",
        "# add applications encoding existing attacker knowledge\n",
        "group_1_def = 'DEGREE_1__EMPLOYED_1__agebinned_45,50__SEX_0__MARRIED_1'\n",
        "group_1_elems = [z3.Int('{0}_{1}'.format(group_1_def, i)) for i in range(count_dict[group_1_def])]\n",
        "solver_3.add(z3.Or([elem == 95_000 for elem in group_1_elems]))\n",
        "\n",
        "group_2_def = 'DEGREE_1__EMPLOYED_1__agebinned_45,50__SEX_1__MARRIED_1'\n",
        "solver_3.add(z3.Int( '{0}_{1}'.format(group_2_def, 0)) == 31_000)\n",
        "\n",
        "# get results (models)\n",
        "model_3 = rec.check_solution(solver_3) \n",
        "if model_3:\n",
        "    print('non-private: Satisfied')\n",
        "else:\n",
        "    print('non-private: Unsatisfied')\n",
        "\n",
        "# attempt to resconstruct data\n",
        "recon_data_3 = rec.reconstruct_data(model_3, elem_dict)\n",
        "\n",
        "# compare original and reconstructed data\n",
        "orig_data, recon_data_3, exact_3, within_2k_3, within_5k_3 = rec.compare_data(orig_data, recon_data_3)\n",
        "\n",
        "print('Of 500 total incomes:')\n",
        "print('    {0} % of incomes reconstructed exactly'.format(percentage(exact_3, 500)))\n",
        "print('    {0} % of incomes resconstructed within $2,000'.format(percentage(within_2k_3, 500)))\n",
        "print('    {0} % of incomes resconstructed within $5,000'.format(percentage(within_5k_3, 500)))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstructed records plot with non-private data\n",
        "\n",
        "The following plot shows the amount of records that were exactly reconstructed and reconstructed within the range of 2,000 and 5,000."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df = pd.DataFrame({ '% of Reconstructed records' : [percentage(exact_3, 500), percentage(within_2k_3, 500), percentage(within_5k_3, 500)],\n",
        "                  'Range': [ 'Exactly', 'Within $2,000', 'Within $5,000']})\n",
        "\n",
        "sns.barplot(x = 'Range', y = '% of Reconstructed records', data = df)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title('% of Reconstructed records by range')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protecting Privacy with SmartNoise\r\n",
        "\r\n",
        "The SmartNoise tools allow researchers and analysts to:\r\n",
        "\r\n",
        "1. Use SQL dialect to create differentially private results over tabular data stores\r\n",
        "2. Host a service to compose queries from heterogeneous differential privacy modules (including non-SQL) against shared privacy budget\r\n",
        "2. Perform black-box stochastic testing against differential privacy modules\r\n",
        "\r\n",
        "The SmartNoise system is currently aimed at scenarios where the researcher is trusted by the data owner.\r\n",
        "\r\n",
        "<img align=\"left\" src=\"./images/RespML-DifferentialPrivacy.gif\"/>\r\n",
        "\r\n",
        "### Apply SmartNoise Analysis"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import opendp.smartnoise.core as sn\n",
        "    \n",
        "with sn.Analysis(protect_floating_point=False) as analysis:\n",
        "    data = sn.Dataset(value = list(sample_of_interest['INCOME']), column_names=['INCOME'])\n",
        "    data = sn.resize(sn.to_int(data, lower = 0, upper = 100_000), number_columns = 1, lower = 0, upper = 100_000)\n",
        "    dp_histogram = sn.dp_histogram(\n",
        "        data,\n",
        "        edges = hist_edges,\n",
        "        upper = 500,\n",
        "        null_value = 1_000_000,\n",
        "        privacy_usage = {'epsilon': 1.0}\n",
        "    )\n",
        "analysis.release()\n",
        "priv_hist = list(dp_histogram.value)    \n",
        "\n",
        "# post-process dp histogram\n",
        "priv_hist = [max(0, count) for count in priv_hist]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attack again"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get results (models)\n",
        "priv_model_3 = rec.check_solution(priv_solver_3) \n",
        "if priv_model_3:\n",
        "    print('private: Unsatisfied')\n",
        "else:\n",
        "    print('private: Satisfied')\n",
        "    exact_3 = 0\n",
        "    within_2k_3 = 0\n",
        "    within_5k_3 = 0"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstructed records plot with private data\n",
        "\n",
        "The following plot shows the amount of records that were exactly reconstructed and reconstructed within the range of 2,000 and 5,000."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df = pd.DataFrame({ '% of Reconstructed records' : [percentage(exact_3, 500), percentage(within_2k_3, 500), percentage(within_5k_3, 500)],\n",
        "                  'Range': [ 'Exactly', 'Within $2,000', 'Within $5,000']})\n",
        "\n",
        "sns.barplot(x = 'Range', y = '% of Reconstructed records', data = df)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title('% of Reconstructed records by range')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differential Privacy Impact\n",
        "\n",
        "The following plot demonstrated that although the data was privatized and injected with noise, its distributions stayed very similar having a non-destructive effect over the data usage."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# create data frame for plotting\n",
        "df = pd.DataFrame({'income': [str(cat) for cat in list(binned_income.cat.categories)] * 2,\n",
        "                   'count': non_priv_hist + priv_hist,\n",
        "                   'version': ['non-private'] * len(non_priv_hist) + ['private'] * len(priv_hist)})\n",
        "\n",
        "df\n",
        "\n",
        "sns.barplot(x = 'income', y = 'count', hue = 'version', data = df)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title('Distribution of income for individuals with a degree')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Privatize Dataset\r\n",
        "\r\n",
        "Now that we have explained the benefits of Differential Privacy with SmartNoise, lets privatize our training dataset and register it in our Azure Machine Learning workspace in order for us to leverage it for training a Machine Learning model.\r\n",
        "\r\n",
        "### Non-private dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from opendp.smartnoise.synthesizers.mwem import MWEMSynthesizer\n",
        "\n",
        "df = fetch_data()\n",
        "df"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Private dataset\n",
        "\n",
        "The cell below contains code to privatize our dataset. `MWEMSynthesizer` will privatize our dataset with `epsilon = 3`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "nf = df.to_numpy()\n",
        "\n",
        "#Privatize dataset\n",
        "synth = MWEMSynthesizer(epsilon=3, splits=[[0,1,2],[3,4],[5,6,7],[8],[9]])\n",
        "synth.fit(nf)\n",
        "\n",
        "sample_size = 500\n",
        "synthetic = synth.sample(int(sample_size))\n",
        "synth_df = pd.DataFrame(synthetic, \n",
        "    index=df.index,\n",
        "    columns=df.columns)\n",
        "\n",
        "register_privatized_dataset(synth_df)\n",
        "synth_df"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}